{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/raw/MetaMotion/A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m single_file_acc\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/raw/MetaMotion/A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/raw/MetaMotion/A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv'"
     ]
    }
   ],
   "source": [
    "single_file_acc=pd.read_csv('../../data/raw/MetaMotion/A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob('../../data/raw/MetaMotion/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_file='../../data/raw/MetaMotion\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=files[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant=f.replace(bath_file,\"\").split('-')[0] # A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lable=f.split('-')[1] # banch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catagory =f.split('-')[2].rstrip('123').replace('_MetaWear_2019','') # heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th>time (01:00)</th>\n",
       "      <th>elapsed (s)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1547472420993</td>\n",
       "      <td>2019-01-14T14:27:00.993</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.317</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>-9.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1547472421033</td>\n",
       "      <td>2019-01-14T14:27:01.033</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3.110</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>-9.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1547472421073</td>\n",
       "      <td>2019-01-14T14:27:01.073</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.232</td>\n",
       "      <td>2.134</td>\n",
       "      <td>-2.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1547472421113</td>\n",
       "      <td>2019-01-14T14:27:01.113</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.988</td>\n",
       "      <td>2.195</td>\n",
       "      <td>-11.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1547472421153</td>\n",
       "      <td>2019-01-14T14:27:01.153</td>\n",
       "      <td>0.16</td>\n",
       "      <td>18.354</td>\n",
       "      <td>-7.866</td>\n",
       "      <td>-14.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1547472433593</td>\n",
       "      <td>2019-01-14T14:27:13.593</td>\n",
       "      <td>12.60</td>\n",
       "      <td>6.159</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>1.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1547472433633</td>\n",
       "      <td>2019-01-14T14:27:13.633</td>\n",
       "      <td>12.64</td>\n",
       "      <td>5.976</td>\n",
       "      <td>-1.768</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1547472433673</td>\n",
       "      <td>2019-01-14T14:27:13.673</td>\n",
       "      <td>12.68</td>\n",
       "      <td>9.878</td>\n",
       "      <td>-2.317</td>\n",
       "      <td>1.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1547472433713</td>\n",
       "      <td>2019-01-14T14:27:13.713</td>\n",
       "      <td>12.72</td>\n",
       "      <td>7.683</td>\n",
       "      <td>-1.951</td>\n",
       "      <td>-2.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1547472433753</td>\n",
       "      <td>2019-01-14T14:27:13.753</td>\n",
       "      <td>12.76</td>\n",
       "      <td>9.939</td>\n",
       "      <td>-1.402</td>\n",
       "      <td>3.659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        epoch (ms)             time (01:00)  elapsed (s)  x-axis (deg/s)  \\\n",
       "0    1547472420993  2019-01-14T14:27:00.993         0.00           2.317   \n",
       "1    1547472421033  2019-01-14T14:27:01.033         0.04           3.110   \n",
       "2    1547472421073  2019-01-14T14:27:01.073         0.08           3.232   \n",
       "3    1547472421113  2019-01-14T14:27:01.113         0.12           2.988   \n",
       "4    1547472421153  2019-01-14T14:27:01.153         0.16          18.354   \n",
       "..             ...                      ...          ...             ...   \n",
       "315  1547472433593  2019-01-14T14:27:13.593        12.60           6.159   \n",
       "316  1547472433633  2019-01-14T14:27:13.633        12.64           5.976   \n",
       "317  1547472433673  2019-01-14T14:27:13.673        12.68           9.878   \n",
       "318  1547472433713  2019-01-14T14:27:13.713        12.72           7.683   \n",
       "319  1547472433753  2019-01-14T14:27:13.753        12.76           9.939   \n",
       "\n",
       "     y-axis (deg/s)  z-axis (deg/s)  \n",
       "0            -2.500          -9.695  \n",
       "1            -0.793          -9.207  \n",
       "2             2.134          -2.500  \n",
       "3             2.195         -11.159  \n",
       "4            -7.866         -14.451  \n",
       "..              ...             ...  \n",
       "315          -0.244           1.463  \n",
       "316          -1.768           0.549  \n",
       "317          -2.317           1.037  \n",
       "318          -1.951          -2.439  \n",
       "319          -1.402           3.659  \n",
       "\n",
       "[320 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['participant']=participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category']=catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category']=catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th>time (01:00)</th>\n",
       "      <th>elapsed (s)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "      <th>participant</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1547472420993</td>\n",
       "      <td>2019-01-14T14:27:00.993</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.317</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>-9.695</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1547472421033</td>\n",
       "      <td>2019-01-14T14:27:01.033</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3.110</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>-9.207</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1547472421073</td>\n",
       "      <td>2019-01-14T14:27:01.073</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.232</td>\n",
       "      <td>2.134</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1547472421113</td>\n",
       "      <td>2019-01-14T14:27:01.113</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.988</td>\n",
       "      <td>2.195</td>\n",
       "      <td>-11.159</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1547472421153</td>\n",
       "      <td>2019-01-14T14:27:01.153</td>\n",
       "      <td>0.16</td>\n",
       "      <td>18.354</td>\n",
       "      <td>-7.866</td>\n",
       "      <td>-14.451</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1547472433593</td>\n",
       "      <td>2019-01-14T14:27:13.593</td>\n",
       "      <td>12.60</td>\n",
       "      <td>6.159</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>1.463</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1547472433633</td>\n",
       "      <td>2019-01-14T14:27:13.633</td>\n",
       "      <td>12.64</td>\n",
       "      <td>5.976</td>\n",
       "      <td>-1.768</td>\n",
       "      <td>0.549</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1547472433673</td>\n",
       "      <td>2019-01-14T14:27:13.673</td>\n",
       "      <td>12.68</td>\n",
       "      <td>9.878</td>\n",
       "      <td>-2.317</td>\n",
       "      <td>1.037</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1547472433713</td>\n",
       "      <td>2019-01-14T14:27:13.713</td>\n",
       "      <td>12.72</td>\n",
       "      <td>7.683</td>\n",
       "      <td>-1.951</td>\n",
       "      <td>-2.439</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1547472433753</td>\n",
       "      <td>2019-01-14T14:27:13.753</td>\n",
       "      <td>12.76</td>\n",
       "      <td>9.939</td>\n",
       "      <td>-1.402</td>\n",
       "      <td>3.659</td>\n",
       "      <td>A</td>\n",
       "      <td>heavy2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        epoch (ms)             time (01:00)  elapsed (s)  x-axis (deg/s)  \\\n",
       "0    1547472420993  2019-01-14T14:27:00.993         0.00           2.317   \n",
       "1    1547472421033  2019-01-14T14:27:01.033         0.04           3.110   \n",
       "2    1547472421073  2019-01-14T14:27:01.073         0.08           3.232   \n",
       "3    1547472421113  2019-01-14T14:27:01.113         0.12           2.988   \n",
       "4    1547472421153  2019-01-14T14:27:01.153         0.16          18.354   \n",
       "..             ...                      ...          ...             ...   \n",
       "315  1547472433593  2019-01-14T14:27:13.593        12.60           6.159   \n",
       "316  1547472433633  2019-01-14T14:27:13.633        12.64           5.976   \n",
       "317  1547472433673  2019-01-14T14:27:13.673        12.68           9.878   \n",
       "318  1547472433713  2019-01-14T14:27:13.713        12.72           7.683   \n",
       "319  1547472433753  2019-01-14T14:27:13.753        12.76           9.939   \n",
       "\n",
       "     y-axis (deg/s)  z-axis (deg/s) participant category  \n",
       "0            -2.500          -9.695           A   heavy2  \n",
       "1            -0.793          -9.207           A   heavy2  \n",
       "2             2.134          -2.500           A   heavy2  \n",
       "3             2.195         -11.159           A   heavy2  \n",
       "4            -7.866         -14.451           A   heavy2  \n",
       "..              ...             ...         ...      ...  \n",
       "315          -0.244           1.463           A   heavy2  \n",
       "316          -1.768           0.549           A   heavy2  \n",
       "317          -2.317           1.037           A   heavy2  \n",
       "318          -1.951          -2.439           A   heavy2  \n",
       "319          -1.402           3.659           A   heavy2  \n",
       "\n",
       "[320 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_set=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyr_set=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    participant=f.replace(bath_file,\"\").split('-')[0]# A\n",
    "    lable=f.split('-')[1] # banch\n",
    "    catagory =f.split('-')[2].rstrip('123').replace('_MetaWear_2019','') # heavy\n",
    "\n",
    "    df=pd.read_csv(f)\n",
    "\n",
    "    df['participant']=participant\n",
    "    df['lable']=lable\n",
    "    df['category']=catagory\n",
    "\n",
    "    if 'Accelerometer' in f :\n",
    "        df['set']=acc_set\n",
    "        acc_set+=1\n",
    "        acc_df=pd.concat([acc_df,df])\n",
    "\n",
    "\n",
    "    if 'Gyroscope' in f :\n",
    "        df['set']=gyr_set\n",
    "        gyr_set+=1\n",
    "        gyr_df=pd.concat([gyr_df,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th>time (01:00)</th>\n",
       "      <th>elapsed (s)</th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1547472421400</td>\n",
       "      <td>2019-01-14T14:27:01.400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.796</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1547472421480</td>\n",
       "      <td>2019-01-14T14:27:01.480</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-0.424</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1547472421560</td>\n",
       "      <td>2019-01-14T14:27:01.560</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>0.808</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1547472421640</td>\n",
       "      <td>2019-01-14T14:27:01.640</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1547472421720</td>\n",
       "      <td>2019-01-14T14:27:01.720</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.845</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1547472433480</td>\n",
       "      <td>2019-01-14T14:27:13.480</td>\n",
       "      <td>12.08</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.924</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1547472433560</td>\n",
       "      <td>2019-01-14T14:27:13.560</td>\n",
       "      <td>12.16</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.901</td>\n",
       "      <td>-0.369</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1547472433640</td>\n",
       "      <td>2019-01-14T14:27:13.640</td>\n",
       "      <td>12.24</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.881</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1547472433720</td>\n",
       "      <td>2019-01-14T14:27:13.720</td>\n",
       "      <td>12.32</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.893</td>\n",
       "      <td>-0.373</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1547472433800</td>\n",
       "      <td>2019-01-14T14:27:13.800</td>\n",
       "      <td>12.40</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0.907</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        epoch (ms)             time (01:00)  elapsed (s)  x-axis (g)  \\\n",
       "0    1547472421400  2019-01-14T14:27:01.400         0.00      -0.181   \n",
       "1    1547472421480  2019-01-14T14:27:01.480         0.08      -0.192   \n",
       "2    1547472421560  2019-01-14T14:27:01.560         0.16      -0.203   \n",
       "3    1547472421640  2019-01-14T14:27:01.640         0.24      -0.217   \n",
       "4    1547472421720  2019-01-14T14:27:01.720         0.32      -0.206   \n",
       "..             ...                      ...          ...         ...   \n",
       "151  1547472433480  2019-01-14T14:27:13.480        12.08      -0.094   \n",
       "152  1547472433560  2019-01-14T14:27:13.560        12.16      -0.104   \n",
       "153  1547472433640  2019-01-14T14:27:13.640        12.24      -0.087   \n",
       "154  1547472433720  2019-01-14T14:27:13.720        12.32      -0.094   \n",
       "155  1547472433800  2019-01-14T14:27:13.800        12.40      -0.100   \n",
       "\n",
       "     y-axis (g)  z-axis (g) participant  lable category  set  \n",
       "0         0.796      -0.383           A  bench   heavy2    2  \n",
       "1         0.823      -0.424           A  bench   heavy2    2  \n",
       "2         0.808      -0.421           A  bench   heavy2    2  \n",
       "3         0.833      -0.439           A  bench   heavy2    2  \n",
       "4         0.845      -0.446           A  bench   heavy2    2  \n",
       "..          ...         ...         ...    ...      ...  ...  \n",
       "151       0.924      -0.357           A  bench   heavy2    2  \n",
       "152       0.901      -0.369           A  bench   heavy2    2  \n",
       "153       0.881      -0.374           A  bench   heavy2    2  \n",
       "154       0.893      -0.373           A  bench   heavy2    2  \n",
       "155       0.907      -0.375           A  bench   heavy2    2  \n",
       "\n",
       "[156 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df[acc_df['set']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1547666043834\n",
       "1      1547666043874\n",
       "2      1547666043914\n",
       "3      1547666043954\n",
       "4      1547666043994\n",
       "           ...      \n",
       "487    1547666063314\n",
       "488    1547666063354\n",
       "489    1547666063394\n",
       "490    1547666063434\n",
       "491    1547666063474\n",
       "Name: epoch (ms), Length: 492, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['epoch (ms)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2019-01-16 20:14:03.834\n",
       "1      2019-01-16 20:14:03.874\n",
       "2      2019-01-16 20:14:03.914\n",
       "3      2019-01-16 20:14:03.954\n",
       "4      2019-01-16 20:14:03.994\n",
       "                ...           \n",
       "487    2019-01-16 20:14:23.314\n",
       "488    2019-01-16 20:14:23.354\n",
       "489    2019-01-16 20:14:23.394\n",
       "490    2019-01-16 20:14:23.434\n",
       "491    2019-01-16 20:14:23.474\n",
       "Name: time (01:00), Length: 492, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time (01:00)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 492 entries, 0 to 491\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   epoch (ms)      492 non-null    int64  \n",
      " 1   time (01:00)    492 non-null    object \n",
      " 2   elapsed (s)     492 non-null    float64\n",
      " 3   x-axis (deg/s)  492 non-null    float64\n",
      " 4   y-axis (deg/s)  492 non-null    float64\n",
      " 5   z-axis (deg/s)  492 non-null    float64\n",
      " 6   participant     492 non-null    object \n",
      " 7   lable           492 non-null    object \n",
      " 8   category        492 non-null    object \n",
      " 9   set             492 non-null    int64  \n",
      "dtypes: float64(4), int64(2), object(4)\n",
      "memory usage: 38.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2019-01-16 19:14:03.834\n",
       "1     2019-01-16 19:14:03.874\n",
       "2     2019-01-16 19:14:03.914\n",
       "3     2019-01-16 19:14:03.954\n",
       "4     2019-01-16 19:14:03.994\n",
       "                ...          \n",
       "487   2019-01-16 19:14:23.314\n",
       "488   2019-01-16 19:14:23.354\n",
       "489   2019-01-16 19:14:23.394\n",
       "490   2019-01-16 19:14:23.434\n",
       "491   2019-01-16 19:14:23.474\n",
       "Name: epoch (ms), Length: 492, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['epoch (ms)'],unit= \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "487    1\n",
       "488    1\n",
       "489    1\n",
       "490    1\n",
       "491    1\n",
       "Name: time (01:00), Length: 492, dtype: int32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df[\"time (01:00)\"]).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.index=pd.to_datetime(acc_df['epoch (ms)'],unit= \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyr_df.index=pd.to_datetime(gyr_df['epoch (ms)'],unit= \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th>time (01:00)</th>\n",
       "      <th>elapsed (s)</th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.431</th>\n",
       "      <td>1547219408431</td>\n",
       "      <td>2019-01-11T16:10:08.431</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.511</th>\n",
       "      <td>1547219408511</td>\n",
       "      <td>2019-01-11T16:10:08.511</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.591</th>\n",
       "      <td>1547219408591</td>\n",
       "      <td>2019-01-11T16:10:08.591</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.671</th>\n",
       "      <td>1547219408671</td>\n",
       "      <td>2019-01-11T16:10:08.671</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.751</th>\n",
       "      <td>1547219408751</td>\n",
       "      <td>2019-01-11T16:10:08.751</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.954</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.089</th>\n",
       "      <td>1547666063089</td>\n",
       "      <td>2019-01-16 20:14:23.089</td>\n",
       "      <td>18.96</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.815</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.169</th>\n",
       "      <td>1547666063169</td>\n",
       "      <td>2019-01-16 20:14:23.169</td>\n",
       "      <td>19.04</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.821</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.249</th>\n",
       "      <td>1547666063249</td>\n",
       "      <td>2019-01-16 20:14:23.249</td>\n",
       "      <td>19.12</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.746</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.329</th>\n",
       "      <td>1547666063329</td>\n",
       "      <td>2019-01-16 20:14:23.329</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.824</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.409</th>\n",
       "      <td>1547666063409</td>\n",
       "      <td>2019-01-16 20:14:23.409</td>\n",
       "      <td>19.28</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.826</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23578 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            epoch (ms)             time (01:00)  elapsed (s)  \\\n",
       "epoch (ms)                                                                     \n",
       "2019-01-11 15:10:08.431  1547219408431  2019-01-11T16:10:08.431         0.00   \n",
       "2019-01-11 15:10:08.511  1547219408511  2019-01-11T16:10:08.511         0.08   \n",
       "2019-01-11 15:10:08.591  1547219408591  2019-01-11T16:10:08.591         0.16   \n",
       "2019-01-11 15:10:08.671  1547219408671  2019-01-11T16:10:08.671         0.24   \n",
       "2019-01-11 15:10:08.751  1547219408751  2019-01-11T16:10:08.751         0.32   \n",
       "...                                ...                      ...          ...   \n",
       "2019-01-16 19:14:23.089  1547666063089  2019-01-16 20:14:23.089        18.96   \n",
       "2019-01-16 19:14:23.169  1547666063169  2019-01-16 20:14:23.169        19.04   \n",
       "2019-01-16 19:14:23.249  1547666063249  2019-01-16 20:14:23.249        19.12   \n",
       "2019-01-16 19:14:23.329  1547666063329  2019-01-16 20:14:23.329        19.20   \n",
       "2019-01-16 19:14:23.409  1547666063409  2019-01-16 20:14:23.409        19.28   \n",
       "\n",
       "                         x-axis (g)  y-axis (g)  z-axis (g) participant  \\\n",
       "epoch (ms)                                                                \n",
       "2019-01-11 15:10:08.431       0.010       0.964      -0.087           A   \n",
       "2019-01-11 15:10:08.511       0.000       0.961      -0.069           A   \n",
       "2019-01-11 15:10:08.591       0.001       0.974      -0.087           A   \n",
       "2019-01-11 15:10:08.671      -0.012       0.971      -0.084           A   \n",
       "2019-01-11 15:10:08.751      -0.013       0.954      -0.094           A   \n",
       "...                             ...         ...         ...         ...   \n",
       "2019-01-16 19:14:23.089       0.012       0.596       0.815           E   \n",
       "2019-01-16 19:14:23.169       0.009       0.528       0.821           E   \n",
       "2019-01-16 19:14:23.249       0.015       0.554       0.746           E   \n",
       "2019-01-16 19:14:23.329       0.006       0.574       0.824           E   \n",
       "2019-01-16 19:14:23.409       0.015       0.588       0.826           E   \n",
       "\n",
       "                         lable category  set  \n",
       "epoch (ms)                                    \n",
       "2019-01-11 15:10:08.431  bench    heavy    1  \n",
       "2019-01-11 15:10:08.511  bench    heavy    1  \n",
       "2019-01-11 15:10:08.591  bench    heavy    1  \n",
       "2019-01-11 15:10:08.671  bench    heavy    1  \n",
       "2019-01-11 15:10:08.751  bench    heavy    1  \n",
       "...                        ...      ...  ...  \n",
       "2019-01-16 19:14:23.089  squat    heavy   94  \n",
       "2019-01-16 19:14:23.169  squat    heavy   94  \n",
       "2019-01-16 19:14:23.249  squat    heavy   94  \n",
       "2019-01-16 19:14:23.329  squat    heavy   94  \n",
       "2019-01-16 19:14:23.409  squat    heavy   94  \n",
       "\n",
       "[23578 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del acc_df['epoch (ms)']\n",
    "del acc_df['time (01:00)']\n",
    "del acc_df['elapsed (s)']\n",
    "\n",
    "del gyr_df['epoch (ms)']\n",
    "del gyr_df['time (01:00)']\n",
    "del gyr_df['elapsed (s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_files(files):\n",
    "\n",
    "    acc_df=pd.DataFrame()\n",
    "    gyr_df=pd.DataFrame()\n",
    "\n",
    "    acc_set=1\n",
    "    gyr_set=1\n",
    "\n",
    "\n",
    "    for f in files:\n",
    "        participant=f.replace(bath_file,\"\").split('-')[0]# A\n",
    "        lable=f.split('-')[1] # banch\n",
    "        catagory =f.split('-')[2].rstrip('123').replace('_MetaWear_2019','') # heavy\n",
    "\n",
    "        df=pd.read_csv(f)\n",
    "\n",
    "        df['participant']=participant\n",
    "        df['lable']=lable\n",
    "        df['category']=catagory\n",
    "\n",
    "        if 'Accelerometer' in f :\n",
    "            df['set']=acc_set\n",
    "            acc_set+=1\n",
    "            acc_df=pd.concat([acc_df,df])\n",
    "\n",
    "\n",
    "        if 'Gyroscope' in f :\n",
    "            df['set']=gyr_set\n",
    "            gyr_set+=1\n",
    "            gyr_df=pd.concat([gyr_df,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc_df,gyr_df\u001b[39m=\u001b[39mread_data_from_files(files)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "acc_df,gyr_df=read_data_from_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (<ipython-input-57-cb1f70c9acaf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[57], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    for f in files:\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "for f in files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/raw/MetaMotion\\\\A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-bench-heavy2_MetaWear_2019-01-14T14.27.00.784_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-bench-heavy2_MetaWear_2019-01-14T14.27.00.784_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-bench-heavy3-rpe8_MetaWear_2019-01-11T16.14.45.178_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-bench-heavy3-rpe8_MetaWear_2019-01-11T16.14.45.178_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-bench-heavy_MetaWear_2019-01-14T14.22.49.165_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-bench-heavy_MetaWear_2019-01-14T14.22.49.165_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-heavy_MetaWear_2019-01-15T20.35.27.174_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-heavy_MetaWear_2019-01-15T20.35.27.174_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-medium1-rpe6_MetaWear_2019-01-11T17.24.24.832_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-medium1-rpe6_MetaWear_2019-01-11T17.24.24.832_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-medium_MetaWear_2019-01-15T20.26.26.347_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-medium_MetaWear_2019-01-15T20.26.26.347_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-medium_MetaWear_2019-01-15T20.30.34.601_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-dead-medium_MetaWear_2019-01-15T20.30.34.601_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy1-rpe8_MetaWear_2019-01-11T16.38.54.580_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy1-rpe8_MetaWear_2019-01-11T16.38.54.580_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy2-rpe7_MetaWear_2019-01-11T16.41.24.439_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy2-rpe7_MetaWear_2019-01-11T16.41.24.439_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy3-rpe7_MetaWear_2019-01-11T16.44.00.801_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy3-rpe7_MetaWear_2019-01-11T16.44.00.801_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy_MetaWear_2019-01-14T14.49.46.484_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy_MetaWear_2019-01-14T14.49.46.484_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy_MetaWear_2019-01-14T14.53.06.282_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy_MetaWear_2019-01-14T14.53.06.282_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy_MetaWear_2019-01-14T14.55.42.246_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-heavy_MetaWear_2019-01-14T14.55.42.246_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-medium1-rpe7_MetaWear_2019-01-11T16.53.53.376_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-medium1-rpe7_MetaWear_2019-01-11T16.53.53.376_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-medium2-rpe7_MetaWear_2019-01-11T16.57.30.113_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-medium2-rpe7_MetaWear_2019-01-11T16.57.30.113_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-medium3-rpe7_MetaWear_2019-01-11T17.00.49.801_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-ohp-medium3-rpe7_MetaWear_2019-01-11T17.00.49.801_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-row-heavy_MetaWear_2019-01-14T15.04.06.123_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-row-heavy_MetaWear_2019-01-14T15.04.06.123_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-row-heavy_MetaWear_2019-01-14T15.06.50.281_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-row-heavy_MetaWear_2019-01-14T15.06.50.281_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-heavy_MetaWear_2019-01-15T20.04.08.637_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-heavy_MetaWear_2019-01-15T20.04.08.637_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-heavy_MetaWear_2019-01-15T20.09.06.903_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-heavy_MetaWear_2019-01-15T20.09.06.903_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-heavy_MetaWear_2019-01-15T20.14.03.633_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-heavy_MetaWear_2019-01-15T20.14.03.633_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-medium1-rpe7_MetaWear_2019-01-11T17.05.44.498_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-medium1-rpe7_MetaWear_2019-01-11T17.05.44.498_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-medium2-rpe8_MetaWear_2019-01-11T17.17.15.443_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-medium2-rpe8_MetaWear_2019-01-11T17.17.15.443_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-medium3-rpe7_MetaWear_2019-01-11T17.19.34.896_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\A-squat-medium3-rpe7_MetaWear_2019-01-11T17.19.34.896_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-bench-heavy1-rpe8_MetaWear_2019-01-11T16.08.04.758_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-bench-heavy1-rpe8_MetaWear_2019-01-11T16.08.04.758_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-bench-heavy2-rpe8_MetaWear_2019-01-11T16.12.04.794_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-bench-heavy2-rpe8_MetaWear_2019-01-11T16.12.04.794_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-heavy1-rpe8_MetaWear_2019-01-11T16.40.07.902_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-heavy1-rpe8_MetaWear_2019-01-11T16.40.07.902_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-heavy2-rpe7_MetaWear_2019-01-11T16.42.43.398_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-heavy2-rpe7_MetaWear_2019-01-11T16.42.43.398_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-heavy3-rpe8_MetaWear_2019-01-11T16.45.55.708_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-heavy3-rpe8_MetaWear_2019-01-11T16.45.55.708_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-medium1-rpe8_MetaWear_2019-01-11T16.48.54.290_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-medium1-rpe8_MetaWear_2019-01-11T16.48.54.290_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-medium2-rpe8_MetaWear_2019-01-11T16.55.53.154_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-medium2-rpe8_MetaWear_2019-01-11T16.55.53.154_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-medium3-rpe9_MetaWear_2019-01-11T16.59.28.181_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-ohp-medium3-rpe9_MetaWear_2019-01-11T16.59.28.181_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-squat-medium1-rpe9_MetaWear_2019-01-11T17.09.32.694_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\B-squat-medium1-rpe9_MetaWear_2019-01-11T17.09.32.694_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-bench-heavy1_MetaWear_2019-01-14T14.29.37.418_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-bench-heavy1_MetaWear_2019-01-14T14.29.37.418_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-bench-heavy2_MetaWear_2019-01-14T14.32.11.392_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-bench-heavy2_MetaWear_2019-01-14T14.32.11.392_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-bench-heavy_MetaWear_2019-01-14T14.51.27.130_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-bench-heavy_MetaWear_2019-01-14T14.51.27.130_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-dead-medium_MetaWear_2019-01-15T20.28.15.269_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-dead-medium_MetaWear_2019-01-15T20.28.15.269_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-dead-medium_MetaWear_2019-01-15T20.32.32.136_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-dead-medium_MetaWear_2019-01-15T20.32.32.136_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-dead-medium_MetaWear_2019-01-15T20.37.17.794_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-dead-medium_MetaWear_2019-01-15T20.37.17.794_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-ohp-heavy_MetaWear_2019-01-14T14.54.34.321_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-ohp-heavy_MetaWear_2019-01-14T14.54.34.321_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-ohp-heavy_MetaWear_2019-01-14T14.57.26.702_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-ohp-heavy_MetaWear_2019-01-14T14.57.26.702_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.05.36.986_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.05.36.986_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.05.36.986_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.05.36.986_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.08.50.111_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.08.50.111_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.08.50.111_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-heavy_MetaWear_2019-01-14T15.08.50.111_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-medium_MetaWear_2019-01-14T15.01.39.689_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-medium_MetaWear_2019-01-14T15.01.39.689_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-medium_MetaWear_2019-01-14T15.01.39.689_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-row-medium_MetaWear_2019-01-14T15.01.39.689_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-squat-heavy_MetaWear_2019-01-15T20.06.31.280_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-squat-heavy_MetaWear_2019-01-15T20.06.31.280_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-squat-heavy_MetaWear_2019-01-15T20.11.55.634_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-squat-heavy_MetaWear_2019-01-15T20.11.55.634_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-squat-heavy_MetaWear_2019-01-15T20.17.27.856_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\C-squat-heavy_MetaWear_2019-01-15T20.17.27.856_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-bench-medium_MetaWear_2019-01-18T18.12.13.952_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-bench-medium_MetaWear_2019-01-18T18.12.13.952_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-bench-medium_MetaWear_2019-01-18T18.21.29.033_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-bench-medium_MetaWear_2019-01-18T18.21.29.033_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-bench-medium_MetaWear_2019-01-18T18.24.19.109_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-bench-medium_MetaWear_2019-01-18T18.24.19.109_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-row-medium_MetaWear_2019-01-18T18.30.48.777_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-row-medium_MetaWear_2019-01-18T18.30.48.777_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-row-medium_MetaWear_2019-01-18T18.33.07.895_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-row-medium_MetaWear_2019-01-18T18.33.07.895_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-row-medium_MetaWear_2019-01-18T18.34.52.516_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-row-medium_MetaWear_2019-01-18T18.34.52.516_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-squat-heavy_MetaWear_2019-01-18T18.03.51.096_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-squat-heavy_MetaWear_2019-01-18T18.03.51.096_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-squat-medium_MetaWear_2019-01-18T17.45.47.575_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-squat-medium_MetaWear_2019-01-18T17.45.47.575_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-squat-medium_MetaWear_2019-01-18T17.51.40.910_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\D-squat-medium_MetaWear_2019-01-18T17.51.40.910_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy2_MetaWear_2019-01-14T14.27.00.784_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy2_MetaWear_2019-01-14T14.27.00.784_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy3-rpe8_MetaWear_2019-01-11T16.14.45.178_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy3-rpe8_MetaWear_2019-01-11T16.14.45.178_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy_MetaWear_2019-01-14T14.22.49.165_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-heavy_MetaWear_2019-01-14T14.22.49.165_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-medium_MetaWear_2019-01-18T18.12.13.952_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-medium_MetaWear_2019-01-18T18.12.13.952_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-medium_MetaWear_2019-01-18T18.21.29.033_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-medium_MetaWear_2019-01-18T18.21.29.033_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-medium_MetaWear_2019-01-18T18.24.19.109_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-bench-medium_MetaWear_2019-01-18T18.24.19.109_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-heavy_MetaWear_2019-01-15T20.35.27.174_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-heavy_MetaWear_2019-01-15T20.35.27.174_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-medium1-rpe6_MetaWear_2019-01-11T17.24.24.832_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-medium1-rpe6_MetaWear_2019-01-11T17.24.24.832_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-medium_MetaWear_2019-01-15T20.26.26.347_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-medium_MetaWear_2019-01-15T20.26.26.347_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-medium_MetaWear_2019-01-15T20.30.34.601_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-dead-medium_MetaWear_2019-01-15T20.30.34.601_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-ohp-heavy_MetaWear_2019-01-14T14.49.46.484_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-ohp-heavy_MetaWear_2019-01-14T14.49.46.484_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-ohp-heavy_MetaWear_2019-01-14T14.53.06.282_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-ohp-heavy_MetaWear_2019-01-14T14.53.06.282_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-ohp-heavy_MetaWear_2019-01-14T14.55.42.246_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-ohp-heavy_MetaWear_2019-01-14T14.55.42.246_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-sitting_MetaWear_2019-01-18T18.22.25.565_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-rest-standing_MetaWear_2019-01-18T18.25.39.382_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.04.06.123_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.04.06.123_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.04.06.123_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.04.06.123_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.06.50.281_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.06.50.281_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.06.50.281_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-heavy_MetaWear_2019-01-14T15.06.50.281_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.30.48.777_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.30.48.777_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.30.48.777_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.30.48.777_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.33.07.895_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.33.07.895_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.33.07.895_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.33.07.895_C42732BE255C_Gyroscope_25.000Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.34.52.516_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.34.52.516_C42732BE255C_Accelerometer_12.500Hz_1.4.41.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-row-medium_MetaWear_2019-01-18T18.34.52.516_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-squat-heavy_MetaWear_2019-01-15T20.09.06.903_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-squat-heavy_MetaWear_2019-01-15T20.09.06.903_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-squat-heavy_MetaWear_2019-01-15T20.14.03.633_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv',\n",
       " '../../data/raw/MetaMotion\\\\E-squat-heavy_MetaWear_2019-01-15T20.14.03.633_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc_df,gyr_df\u001b[39m=\u001b[39mread_data_from_files(files)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "acc_df,gyr_df=read_data_from_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.431</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.511</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.591</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.671</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.751</th>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.954</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.089</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.815</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.169</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.821</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.249</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.746</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.329</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.824</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.409</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.826</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23578 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g) participant  \\\n",
       "epoch (ms)                                                                \n",
       "2019-01-11 15:10:08.431       0.010       0.964      -0.087           A   \n",
       "2019-01-11 15:10:08.511       0.000       0.961      -0.069           A   \n",
       "2019-01-11 15:10:08.591       0.001       0.974      -0.087           A   \n",
       "2019-01-11 15:10:08.671      -0.012       0.971      -0.084           A   \n",
       "2019-01-11 15:10:08.751      -0.013       0.954      -0.094           A   \n",
       "...                             ...         ...         ...         ...   \n",
       "2019-01-16 19:14:23.089       0.012       0.596       0.815           E   \n",
       "2019-01-16 19:14:23.169       0.009       0.528       0.821           E   \n",
       "2019-01-16 19:14:23.249       0.015       0.554       0.746           E   \n",
       "2019-01-16 19:14:23.329       0.006       0.574       0.824           E   \n",
       "2019-01-16 19:14:23.409       0.015       0.588       0.826           E   \n",
       "\n",
       "                         lable category  set  \n",
       "epoch (ms)                                    \n",
       "2019-01-11 15:10:08.431  bench    heavy    1  \n",
       "2019-01-11 15:10:08.511  bench    heavy    1  \n",
       "2019-01-11 15:10:08.591  bench    heavy    1  \n",
       "2019-01-11 15:10:08.671  bench    heavy    1  \n",
       "2019-01-11 15:10:08.751  bench    heavy    1  \n",
       "...                        ...      ...  ...  \n",
       "2019-01-16 19:14:23.089  squat    heavy   94  \n",
       "2019-01-16 19:14:23.169  squat    heavy   94  \n",
       "2019-01-16 19:14:23.249  squat    heavy   94  \n",
       "2019-01-16 19:14:23.329  squat    heavy   94  \n",
       "2019-01-16 19:14:23.409  squat    heavy   94  \n",
       "\n",
       "[23578 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_files(files):\n",
    "\n",
    "    acc_df=pd.DataFrame()\n",
    "    gyr_df=pd.DataFrame()\n",
    "\n",
    "    acc_set=1\n",
    "    gyr_set=1\n",
    "\n",
    "\n",
    "    for f in files:\n",
    "        participant=f.replace(bath_file,\"\").split('-')[0]# A\n",
    "        lable=f.split('-')[1] # banch\n",
    "        catagory =f.split('-')[2].rstrip('123').replace('_MetaWear_2019','') # heavy\n",
    "\n",
    "        df=pd.read_csv(f)\n",
    "\n",
    "        df['participant']=participant\n",
    "        df['lable']=lable\n",
    "        df['category']=catagory\n",
    "\n",
    "        if 'Accelerometer' in f :\n",
    "            df['set']=acc_set\n",
    "            acc_set+=1\n",
    "            acc_df=pd.concat([acc_df,df])\n",
    "\n",
    "\n",
    "        if 'Gyroscope' in f :\n",
    "            df['set']=gyr_set\n",
    "            gyr_set+=1\n",
    "            gyr_df=pd.concat([gyr_df,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'epoch (ms)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'epoch (ms)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m acc_df\u001b[39m.\u001b[39mindex\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mto_datetime(acc_df[\u001b[39m'\u001b[39;49m\u001b[39mepoch (ms)\u001b[39;49m\u001b[39m'\u001b[39;49m],unit\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'epoch (ms)'"
     ]
    }
   ],
   "source": [
    "acc_df.index=pd.to_datetime(acc_df['epoch (ms)'],unit= \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_files(files):\n",
    "\n",
    "    acc_df=pd.DataFrame()\n",
    "    gyr_df=pd.DataFrame()\n",
    "\n",
    "    acc_set=1\n",
    "    gyr_set=1\n",
    "\n",
    "\n",
    "    for f in files:\n",
    "        participant=f.replace(bath_file,\"\").split('-')[0]# A\n",
    "        lable=f.split('-')[1] # banch\n",
    "        catagory =f.split('-')[2].rstrip('123').replace('_MetaWear_2019','') # heavy\n",
    "\n",
    "        df=pd.read_csv(f)\n",
    "\n",
    "        df['participant']=participant\n",
    "        df['lable']=lable\n",
    "        df['category']=catagory\n",
    "\n",
    "        if 'Accelerometer' in f :\n",
    "            df['set']=acc_set\n",
    "            acc_set+=1\n",
    "            acc_df=pd.concat([acc_df,df])\n",
    "\n",
    "\n",
    "        if 'Gyroscope' in f :\n",
    "            df['set']=gyr_set\n",
    "            gyr_set+=1\n",
    "            gyr_df=pd.concat([gyr_df,df])\n",
    "\n",
    "        # set the time as index \n",
    "    acc_df.index=pd.to_datetime(acc_df['epoch (ms)'],unit= \"ms\") \n",
    "    gyr_df.index=pd.to_datetime(gyr_df['epoch (ms)'],unit= \"ms\") \n",
    "\n",
    "\n",
    "    del acc_df['epoch (ms)']\n",
    "    del acc_df['time (01:00)']\n",
    "    del acc_df['elapsed (s)']\n",
    "\n",
    "    del gyr_df['epoch (ms)']\n",
    "    del gyr_df['time (01:00)']\n",
    "    del gyr_df['elapsed (s)']\n",
    "\n",
    "    return acc_df,gyr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df,gyr_df=read_data_from_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged=pd.concat([acc_df.iloc[:,:3],gyr_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.431</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.511</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.591</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.671</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.751</th>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.954</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.089</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.815</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.169</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.821</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.249</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.746</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.329</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.824</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-16 19:14:23.409</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.826</td>\n",
       "      <td>E</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23578 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g) participant  \\\n",
       "epoch (ms)                                                                \n",
       "2019-01-11 15:10:08.431       0.010       0.964      -0.087           A   \n",
       "2019-01-11 15:10:08.511       0.000       0.961      -0.069           A   \n",
       "2019-01-11 15:10:08.591       0.001       0.974      -0.087           A   \n",
       "2019-01-11 15:10:08.671      -0.012       0.971      -0.084           A   \n",
       "2019-01-11 15:10:08.751      -0.013       0.954      -0.094           A   \n",
       "...                             ...         ...         ...         ...   \n",
       "2019-01-16 19:14:23.089       0.012       0.596       0.815           E   \n",
       "2019-01-16 19:14:23.169       0.009       0.528       0.821           E   \n",
       "2019-01-16 19:14:23.249       0.015       0.554       0.746           E   \n",
       "2019-01-16 19:14:23.329       0.006       0.574       0.824           E   \n",
       "2019-01-16 19:14:23.409       0.015       0.588       0.826           E   \n",
       "\n",
       "                         lable category  set  \n",
       "epoch (ms)                                    \n",
       "2019-01-11 15:10:08.431  bench    heavy    1  \n",
       "2019-01-11 15:10:08.511  bench    heavy    1  \n",
       "2019-01-11 15:10:08.591  bench    heavy    1  \n",
       "2019-01-11 15:10:08.671  bench    heavy    1  \n",
       "2019-01-11 15:10:08.751  bench    heavy    1  \n",
       "...                        ...      ...  ...  \n",
       "2019-01-16 19:14:23.089  squat    heavy   94  \n",
       "2019-01-16 19:14:23.169  squat    heavy   94  \n",
       "2019-01-16 19:14:23.249  squat    heavy   94  \n",
       "2019-01-16 19:14:23.329  squat    heavy   94  \n",
       "2019-01-16 19:14:23.409  squat    heavy   94  \n",
       "\n",
       "[23578 rows x 7 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_lst_1 = pd.date_range(\"2020-01-06\", \"2020-04-03\", freq=\"MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.671</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>5.976</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.720</td>\n",
       "      <td>-2.073</td>\n",
       "      <td>3.171</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488</td>\n",
       "      <td>-3.537</td>\n",
       "      <td>-4.146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.070</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-5.854</td>\n",
       "      <td>3.537</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.805</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.382</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.462</th>\n",
       "      <td>-0.035</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.542</th>\n",
       "      <td>-0.045</td>\n",
       "      <td>-1.029</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.622</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.702</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-1.031</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69677 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g)  x-axis (deg/s)  \\\n",
       "epoch (ms)                                                                    \n",
       "2019-01-11 15:08:04.950         NaN         NaN         NaN         -10.671   \n",
       "2019-01-11 15:08:04.990         NaN         NaN         NaN          -8.720   \n",
       "2019-01-11 15:08:05.030         NaN         NaN         NaN           0.488   \n",
       "2019-01-11 15:08:05.070         NaN         NaN         NaN           0.244   \n",
       "2019-01-11 15:08:05.110         NaN         NaN         NaN          -0.915   \n",
       "...                             ...         ...         ...             ...   \n",
       "2019-01-20 17:35:13.382      -0.060      -1.021      -0.058             NaN   \n",
       "2019-01-20 17:35:13.462      -0.035      -1.037      -0.026             NaN   \n",
       "2019-01-20 17:35:13.542      -0.045      -1.029      -0.033             NaN   \n",
       "2019-01-20 17:35:13.622      -0.039      -1.027      -0.039             NaN   \n",
       "2019-01-20 17:35:13.702      -0.049      -1.031      -0.049             NaN   \n",
       "\n",
       "                         y-axis (deg/s)  z-axis (deg/s) participant  lable  \\\n",
       "epoch (ms)                                                                   \n",
       "2019-01-11 15:08:04.950          -1.524           5.976           B  bench   \n",
       "2019-01-11 15:08:04.990          -2.073           3.171           B  bench   \n",
       "2019-01-11 15:08:05.030          -3.537          -4.146           B  bench   \n",
       "2019-01-11 15:08:05.070          -5.854           3.537           B  bench   \n",
       "2019-01-11 15:08:05.110           0.061          -2.805           B  bench   \n",
       "...                                 ...             ...         ...    ...   \n",
       "2019-01-20 17:35:13.382             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.462             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.542             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.622             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.702             NaN             NaN         NaN    NaN   \n",
       "\n",
       "                        category   set  \n",
       "epoch (ms)                              \n",
       "2019-01-11 15:08:04.950    heavy  30.0  \n",
       "2019-01-11 15:08:04.990    heavy  30.0  \n",
       "2019-01-11 15:08:05.030    heavy  30.0  \n",
       "2019-01-11 15:08:05.070    heavy  30.0  \n",
       "2019-01-11 15:08:05.110    heavy  30.0  \n",
       "...                          ...   ...  \n",
       "2019-01-20 17:35:13.382      NaN   NaN  \n",
       "2019-01-20 17:35:13.462      NaN   NaN  \n",
       "2019-01-20 17:35:13.542      NaN   NaN  \n",
       "2019-01-20 17:35:13.622      NaN   NaN  \n",
       "2019-01-20 17:35:13.702      NaN   NaN  \n",
       "\n",
       "[69677 rows x 10 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.431</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-8.110</td>\n",
       "      <td>-4.024</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.511</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>1.524</td>\n",
       "      <td>-2.561</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.591</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.974</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>1.707</td>\n",
       "      <td>-5.366</td>\n",
       "      <td>0.915</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.671</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.971</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>2.683</td>\n",
       "      <td>-4.146</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:08.751</th>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.954</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>1.524</td>\n",
       "      <td>0.610</td>\n",
       "      <td>-3.171</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-15 19:04:25.561</th>\n",
       "      <td>0.369</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.761</td>\n",
       "      <td>11.220</td>\n",
       "      <td>-5.061</td>\n",
       "      <td>-5.061</td>\n",
       "      <td>A</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-15 19:04:25.641</th>\n",
       "      <td>0.387</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.776</td>\n",
       "      <td>3.963</td>\n",
       "      <td>-2.988</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>A</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-15 19:04:25.721</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.680</td>\n",
       "      <td>15.305</td>\n",
       "      <td>-3.293</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>A</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-15 19:04:25.801</th>\n",
       "      <td>0.353</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.635</td>\n",
       "      <td>30.366</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>-4.573</td>\n",
       "      <td>A</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-15 19:04:25.881</th>\n",
       "      <td>0.359</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.678</td>\n",
       "      <td>14.756</td>\n",
       "      <td>-6.585</td>\n",
       "      <td>-2.378</td>\n",
       "      <td>A</td>\n",
       "      <td>squat</td>\n",
       "      <td>heavy</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1119 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g)  x-axis (deg/s)  \\\n",
       "epoch (ms)                                                                    \n",
       "2019-01-11 15:10:08.431       0.010       0.964      -0.087           2.622   \n",
       "2019-01-11 15:10:08.511       0.000       0.961      -0.069           1.524   \n",
       "2019-01-11 15:10:08.591       0.001       0.974      -0.087           1.707   \n",
       "2019-01-11 15:10:08.671      -0.012       0.971      -0.084           2.683   \n",
       "2019-01-11 15:10:08.751      -0.013       0.954      -0.094           1.524   \n",
       "...                             ...         ...         ...             ...   \n",
       "2019-01-15 19:04:25.561       0.369       0.591       0.761          11.220   \n",
       "2019-01-15 19:04:25.641       0.387       0.566       0.776           3.963   \n",
       "2019-01-15 19:04:25.721       0.361       0.574       0.680          15.305   \n",
       "2019-01-15 19:04:25.801       0.353       0.583       0.635          30.366   \n",
       "2019-01-15 19:04:25.881       0.359       0.605       0.678          14.756   \n",
       "\n",
       "                         y-axis (deg/s)  z-axis (deg/s) participant  lable  \\\n",
       "epoch (ms)                                                                   \n",
       "2019-01-11 15:10:08.431          -8.110          -4.024           A  bench   \n",
       "2019-01-11 15:10:08.511          -2.561          -2.500           A  bench   \n",
       "2019-01-11 15:10:08.591          -5.366           0.915           A  bench   \n",
       "2019-01-11 15:10:08.671          -4.146          -1.220           A  bench   \n",
       "2019-01-11 15:10:08.751           0.610          -3.171           A  bench   \n",
       "...                                 ...             ...         ...    ...   \n",
       "2019-01-15 19:04:25.561          -5.061          -5.061           A  squat   \n",
       "2019-01-15 19:04:25.641          -2.988          -0.793           A  squat   \n",
       "2019-01-15 19:04:25.721          -3.293          -0.671           A  squat   \n",
       "2019-01-15 19:04:25.801          -0.122          -4.573           A  squat   \n",
       "2019-01-15 19:04:25.881          -6.585          -2.378           A  squat   \n",
       "\n",
       "                        category   set  \n",
       "epoch (ms)                              \n",
       "2019-01-11 15:10:08.431    heavy   1.0  \n",
       "2019-01-11 15:10:08.511    heavy   1.0  \n",
       "2019-01-11 15:10:08.591    heavy   1.0  \n",
       "2019-01-11 15:10:08.671    heavy   1.0  \n",
       "2019-01-11 15:10:08.751    heavy   1.0  \n",
       "...                          ...   ...  \n",
       "2019-01-15 19:04:25.561    heavy  24.0  \n",
       "2019-01-15 19:04:25.641    heavy  24.0  \n",
       "2019-01-15 19:04:25.721    heavy  24.0  \n",
       "2019-01-15 19:04:25.801    heavy  24.0  \n",
       "2019-01-15 19:04:25.881    heavy  24.0  \n",
       "\n",
       "[1119 rows x 10 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged=pd.concat([acc_df.iloc[:,:3],gyr_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.671</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>5.976</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.720</td>\n",
       "      <td>-2.073</td>\n",
       "      <td>3.171</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488</td>\n",
       "      <td>-3.537</td>\n",
       "      <td>-4.146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.070</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-5.854</td>\n",
       "      <td>3.537</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.805</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.590</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.744</td>\n",
       "      <td>-9.512</td>\n",
       "      <td>-19.756</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.630</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.073</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>-7.378</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.634</th>\n",
       "      <td>-0.232</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.939</td>\n",
       "      <td>-6.402</td>\n",
       "      <td>12.256</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.710</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>2.988</td>\n",
       "      <td>-2.134</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g)  x-axis (deg/s)  \\\n",
       "epoch (ms)                                                                    \n",
       "2019-01-11 15:08:04.950         NaN         NaN         NaN         -10.671   \n",
       "2019-01-11 15:08:04.990         NaN         NaN         NaN          -8.720   \n",
       "2019-01-11 15:08:05.030         NaN         NaN         NaN           0.488   \n",
       "2019-01-11 15:08:05.070         NaN         NaN         NaN           0.244   \n",
       "2019-01-11 15:08:05.110         NaN         NaN         NaN          -0.915   \n",
       "...                             ...         ...         ...             ...   \n",
       "2019-01-11 15:08:07.590         NaN         NaN         NaN          12.744   \n",
       "2019-01-11 15:08:07.630         NaN         NaN         NaN           7.073   \n",
       "2019-01-11 15:08:07.634      -0.232         0.9      -0.186             NaN   \n",
       "2019-01-11 15:08:07.670         NaN         NaN         NaN           9.939   \n",
       "2019-01-11 15:08:07.710         NaN         NaN         NaN          -0.915   \n",
       "\n",
       "                         y-axis (deg/s)  z-axis (deg/s) participant  lable  \\\n",
       "epoch (ms)                                                                   \n",
       "2019-01-11 15:08:04.950          -1.524           5.976           B  bench   \n",
       "2019-01-11 15:08:04.990          -2.073           3.171           B  bench   \n",
       "2019-01-11 15:08:05.030          -3.537          -4.146           B  bench   \n",
       "2019-01-11 15:08:05.070          -5.854           3.537           B  bench   \n",
       "2019-01-11 15:08:05.110           0.061          -2.805           B  bench   \n",
       "...                                 ...             ...         ...    ...   \n",
       "2019-01-11 15:08:07.590          -9.512         -19.756           B  bench   \n",
       "2019-01-11 15:08:07.630          -1.220          -7.378           B  bench   \n",
       "2019-01-11 15:08:07.634             NaN             NaN         NaN    NaN   \n",
       "2019-01-11 15:08:07.670          -6.402          12.256           B  bench   \n",
       "2019-01-11 15:08:07.710           2.988          -2.134           B  bench   \n",
       "\n",
       "                        category   set  \n",
       "epoch (ms)                              \n",
       "2019-01-11 15:08:04.950    heavy  30.0  \n",
       "2019-01-11 15:08:04.990    heavy  30.0  \n",
       "2019-01-11 15:08:05.030    heavy  30.0  \n",
       "2019-01-11 15:08:05.070    heavy  30.0  \n",
       "2019-01-11 15:08:05.110    heavy  30.0  \n",
       "...                          ...   ...  \n",
       "2019-01-11 15:08:07.590    heavy  30.0  \n",
       "2019-01-11 15:08:07.630    heavy  30.0  \n",
       "2019-01-11 15:08:07.634      NaN   NaN  \n",
       "2019-01-11 15:08:07.670    heavy  30.0  \n",
       "2019-01-11 15:08:07.710    heavy  30.0  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Of the four parameters: start, end, periods, and freq, exactly three must be specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_list1\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mdate_range([\u001b[39m'\u001b[39;49m\u001b[39m2019-01-11 15:08:07.590\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39m2019-01-11 15:08:07.710\u001b[39;49m\u001b[39m'\u001b[39;49m],freq\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mms\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:1009\u001b[0m, in \u001b[0;36mdate_range\u001b[1;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[39mif\u001b[39;00m freq \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m com\u001b[39m.\u001b[39many_none(periods, start, end):\n\u001b[0;32m   1007\u001b[0m     freq \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1009\u001b[0m dtarr \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39;49m_generate_range(\n\u001b[0;32m   1010\u001b[0m     start\u001b[39m=\u001b[39;49mstart,\n\u001b[0;32m   1011\u001b[0m     end\u001b[39m=\u001b[39;49mend,\n\u001b[0;32m   1012\u001b[0m     periods\u001b[39m=\u001b[39;49mperiods,\n\u001b[0;32m   1013\u001b[0m     freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m   1014\u001b[0m     tz\u001b[39m=\u001b[39;49mtz,\n\u001b[0;32m   1015\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m   1016\u001b[0m     inclusive\u001b[39m=\u001b[39;49minclusive,\n\u001b[0;32m   1017\u001b[0m     unit\u001b[39m=\u001b[39;49munit,\n\u001b[0;32m   1018\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[0;32m   1020\u001b[0m \u001b[39mreturn\u001b[39;00m DatetimeIndex\u001b[39m.\u001b[39m_simple_new(dtarr, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:400\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust provide freq argument if no data is supplied\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mcount_not_none(start, end, periods, freq) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOf the four parameters: start, end, periods, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand freq, exactly three must be specified\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n\u001b[0;32m    404\u001b[0m freq \u001b[39m=\u001b[39m to_offset(freq)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Of the four parameters: start, end, periods, and freq, exactly three must be specified"
     ]
    }
   ],
   "source": [
    "data_list1=pd.date_range(['2019-01-11 15:08:07.590','2019-01-11 15:08:07.710'],freq='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Of the four parameters: start, end, periods, and freq, exactly three must be specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_list1\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mdate_range([\u001b[39m'\u001b[39;49m\u001b[39m2019-01-11 15:08:07.590\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39m2019-01-11 15:08:07.710\u001b[39;49m\u001b[39m'\u001b[39;49m],freq\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mms\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:1009\u001b[0m, in \u001b[0;36mdate_range\u001b[1;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[39mif\u001b[39;00m freq \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m com\u001b[39m.\u001b[39many_none(periods, start, end):\n\u001b[0;32m   1007\u001b[0m     freq \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1009\u001b[0m dtarr \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39;49m_generate_range(\n\u001b[0;32m   1010\u001b[0m     start\u001b[39m=\u001b[39;49mstart,\n\u001b[0;32m   1011\u001b[0m     end\u001b[39m=\u001b[39;49mend,\n\u001b[0;32m   1012\u001b[0m     periods\u001b[39m=\u001b[39;49mperiods,\n\u001b[0;32m   1013\u001b[0m     freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m   1014\u001b[0m     tz\u001b[39m=\u001b[39;49mtz,\n\u001b[0;32m   1015\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m   1016\u001b[0m     inclusive\u001b[39m=\u001b[39;49minclusive,\n\u001b[0;32m   1017\u001b[0m     unit\u001b[39m=\u001b[39;49munit,\n\u001b[0;32m   1018\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[0;32m   1020\u001b[0m \u001b[39mreturn\u001b[39;00m DatetimeIndex\u001b[39m.\u001b[39m_simple_new(dtarr, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:400\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust provide freq argument if no data is supplied\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mcount_not_none(start, end, periods, freq) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOf the four parameters: start, end, periods, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand freq, exactly three must be specified\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n\u001b[0;32m    404\u001b[0m freq \u001b[39m=\u001b[39m to_offset(freq)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Of the four parameters: start, end, periods, and freq, exactly three must be specified"
     ]
    }
   ],
   "source": [
    "data_list1=pd.date_range(['2019-01-11 15:08:07.590','2019-01-11 15:08:07.710'],freq='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Of the four parameters: start, end, periods, and freq, exactly three must be specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_list1\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mdate_range([\u001b[39m'\u001b[39;49m\u001b[39m2019-01-11 15:08:07.590\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39m2019-01-11 15:08:07.710\u001b[39;49m\u001b[39m'\u001b[39;49m],freq\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mms\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:1009\u001b[0m, in \u001b[0;36mdate_range\u001b[1;34m(start, end, periods, freq, tz, normalize, name, inclusive, unit, **kwargs)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[39mif\u001b[39;00m freq \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m com\u001b[39m.\u001b[39many_none(periods, start, end):\n\u001b[0;32m   1007\u001b[0m     freq \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1009\u001b[0m dtarr \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39;49m_generate_range(\n\u001b[0;32m   1010\u001b[0m     start\u001b[39m=\u001b[39;49mstart,\n\u001b[0;32m   1011\u001b[0m     end\u001b[39m=\u001b[39;49mend,\n\u001b[0;32m   1012\u001b[0m     periods\u001b[39m=\u001b[39;49mperiods,\n\u001b[0;32m   1013\u001b[0m     freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m   1014\u001b[0m     tz\u001b[39m=\u001b[39;49mtz,\n\u001b[0;32m   1015\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m   1016\u001b[0m     inclusive\u001b[39m=\u001b[39;49minclusive,\n\u001b[0;32m   1017\u001b[0m     unit\u001b[39m=\u001b[39;49munit,\n\u001b[0;32m   1018\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[0;32m   1020\u001b[0m \u001b[39mreturn\u001b[39;00m DatetimeIndex\u001b[39m.\u001b[39m_simple_new(dtarr, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:400\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive, unit)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust provide freq argument if no data is supplied\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mcount_not_none(start, end, periods, freq) \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOf the four parameters: start, end, periods, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand freq, exactly three must be specified\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n\u001b[0;32m    404\u001b[0m freq \u001b[39m=\u001b[39m to_offset(freq)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Of the four parameters: start, end, periods, and freq, exactly three must be specified"
     ]
    }
   ],
   "source": [
    "data_list1=pd.date_range(['2019-01-11 15:08:07.590','2019-01-11 15:08:07.710'],freq='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.590','2019-01-11 15:08:07.710',freq='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.590000', '2019-01-11 15:08:07.591000',\n",
       "               '2019-01-11 15:08:07.592000', '2019-01-11 15:08:07.593000',\n",
       "               '2019-01-11 15:08:07.594000', '2019-01-11 15:08:07.595000',\n",
       "               '2019-01-11 15:08:07.596000', '2019-01-11 15:08:07.597000',\n",
       "               '2019-01-11 15:08:07.598000', '2019-01-11 15:08:07.599000',\n",
       "               ...\n",
       "               '2019-01-11 15:08:07.701000', '2019-01-11 15:08:07.702000',\n",
       "               '2019-01-11 15:08:07.703000', '2019-01-11 15:08:07.704000',\n",
       "               '2019-01-11 15:08:07.705000', '2019-01-11 15:08:07.706000',\n",
       "               '2019-01-11 15:08:07.707000', '2019-01-11 15:08:07.708000',\n",
       "               '2019-01-11 15:08:07.709000', '2019-01-11 15:08:07.710000'],\n",
       "              dtype='datetime64[ns]', length=121, freq='L')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='500ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.550000'], dtype='datetime64[ns]', freq='500L')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='1000ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.550000'], dtype='datetime64[ns]', freq='1000L')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='10ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.550000', '2019-01-11 15:08:07.560000',\n",
       "               '2019-01-11 15:08:07.570000', '2019-01-11 15:08:07.580000',\n",
       "               '2019-01-11 15:08:07.590000', '2019-01-11 15:08:07.600000',\n",
       "               '2019-01-11 15:08:07.610000', '2019-01-11 15:08:07.620000',\n",
       "               '2019-01-11 15:08:07.630000', '2019-01-11 15:08:07.640000',\n",
       "               '2019-01-11 15:08:07.650000', '2019-01-11 15:08:07.660000',\n",
       "               '2019-01-11 15:08:07.670000', '2019-01-11 15:08:07.680000',\n",
       "               '2019-01-11 15:08:07.690000', '2019-01-11 15:08:07.700000'],\n",
       "              dtype='datetime64[ns]', freq='10L')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='10ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.550000', '2019-01-11 15:08:07.560000',\n",
       "               '2019-01-11 15:08:07.570000', '2019-01-11 15:08:07.580000',\n",
       "               '2019-01-11 15:08:07.590000', '2019-01-11 15:08:07.600000',\n",
       "               '2019-01-11 15:08:07.610000', '2019-01-11 15:08:07.620000',\n",
       "               '2019-01-11 15:08:07.630000', '2019-01-11 15:08:07.640000',\n",
       "               '2019-01-11 15:08:07.650000', '2019-01-11 15:08:07.660000',\n",
       "               '2019-01-11 15:08:07.670000', '2019-01-11 15:08:07.680000',\n",
       "               '2019-01-11 15:08:07.690000', '2019-01-11 15:08:07.700000'],\n",
       "              dtype='datetime64[ns]', freq='10L')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('2019-01-11 15:08:07.550')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'epoch (ms)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'epoch (ms)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_merged[\u001b[39m'\u001b[39;49m\u001b[39mepoch (ms)\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'epoch (ms)'"
     ]
    }
   ],
   "source": [
    "data_merged['epoch (ms)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.671</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>5.976</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.720</td>\n",
       "      <td>-2.073</td>\n",
       "      <td>3.171</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488</td>\n",
       "      <td>-3.537</td>\n",
       "      <td>-4.146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.070</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-5.854</td>\n",
       "      <td>3.537</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.805</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.382</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.462</th>\n",
       "      <td>-0.035</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.542</th>\n",
       "      <td>-0.045</td>\n",
       "      <td>-1.029</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.622</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.702</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-1.031</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69677 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g)  x-axis (deg/s)  \\\n",
       "epoch (ms)                                                                    \n",
       "2019-01-11 15:08:04.950         NaN         NaN         NaN         -10.671   \n",
       "2019-01-11 15:08:04.990         NaN         NaN         NaN          -8.720   \n",
       "2019-01-11 15:08:05.030         NaN         NaN         NaN           0.488   \n",
       "2019-01-11 15:08:05.070         NaN         NaN         NaN           0.244   \n",
       "2019-01-11 15:08:05.110         NaN         NaN         NaN          -0.915   \n",
       "...                             ...         ...         ...             ...   \n",
       "2019-01-20 17:35:13.382      -0.060      -1.021      -0.058             NaN   \n",
       "2019-01-20 17:35:13.462      -0.035      -1.037      -0.026             NaN   \n",
       "2019-01-20 17:35:13.542      -0.045      -1.029      -0.033             NaN   \n",
       "2019-01-20 17:35:13.622      -0.039      -1.027      -0.039             NaN   \n",
       "2019-01-20 17:35:13.702      -0.049      -1.031      -0.049             NaN   \n",
       "\n",
       "                         y-axis (deg/s)  z-axis (deg/s) participant  lable  \\\n",
       "epoch (ms)                                                                   \n",
       "2019-01-11 15:08:04.950          -1.524           5.976           B  bench   \n",
       "2019-01-11 15:08:04.990          -2.073           3.171           B  bench   \n",
       "2019-01-11 15:08:05.030          -3.537          -4.146           B  bench   \n",
       "2019-01-11 15:08:05.070          -5.854           3.537           B  bench   \n",
       "2019-01-11 15:08:05.110           0.061          -2.805           B  bench   \n",
       "...                                 ...             ...         ...    ...   \n",
       "2019-01-20 17:35:13.382             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.462             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.542             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.622             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.702             NaN             NaN         NaN    NaN   \n",
       "\n",
       "                        category   set  \n",
       "epoch (ms)                              \n",
       "2019-01-11 15:08:04.950    heavy  30.0  \n",
       "2019-01-11 15:08:04.990    heavy  30.0  \n",
       "2019-01-11 15:08:05.030    heavy  30.0  \n",
       "2019-01-11 15:08:05.070    heavy  30.0  \n",
       "2019-01-11 15:08:05.110    heavy  30.0  \n",
       "...                          ...   ...  \n",
       "2019-01-20 17:35:13.382      NaN   NaN  \n",
       "2019-01-20 17:35:13.462      NaN   NaN  \n",
       "2019-01-20 17:35:13.542      NaN   NaN  \n",
       "2019-01-20 17:35:13.622      NaN   NaN  \n",
       "2019-01-20 17:35:13.702      NaN   NaN  \n",
       "\n",
       "[69677 rows x 10 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:04.950000', '2019-01-11 15:08:04.990000',\n",
       "               '2019-01-11 15:08:05.030000', '2019-01-11 15:08:05.070000',\n",
       "               '2019-01-11 15:08:05.110000', '2019-01-11 15:08:05.150000',\n",
       "               '2019-01-11 15:08:05.190000', '2019-01-11 15:08:05.230000',\n",
       "               '2019-01-11 15:08:05.270000', '2019-01-11 15:08:05.310000',\n",
       "               ...\n",
       "               '2019-01-20 17:35:12.982000', '2019-01-20 17:35:13.062000',\n",
       "               '2019-01-20 17:35:13.142000', '2019-01-20 17:35:13.222000',\n",
       "               '2019-01-20 17:35:13.302000', '2019-01-20 17:35:13.382000',\n",
       "               '2019-01-20 17:35:13.462000', '2019-01-20 17:35:13.542000',\n",
       "               '2019-01-20 17:35:13.622000', '2019-01-20 17:35:13.702000'],\n",
       "              dtype='datetime64[ns]', name='epoch (ms)', length=69677, freq=None)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='500ns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([   '2019-01-11 15:08:07.550000',\n",
       "               '2019-01-11 15:08:07.550000500',\n",
       "                  '2019-01-11 15:08:07.550001',\n",
       "               '2019-01-11 15:08:07.550001500',\n",
       "                  '2019-01-11 15:08:07.550002',\n",
       "               '2019-01-11 15:08:07.550002500',\n",
       "                  '2019-01-11 15:08:07.550003',\n",
       "               '2019-01-11 15:08:07.550003500',\n",
       "                  '2019-01-11 15:08:07.550004',\n",
       "               '2019-01-11 15:08:07.550004500',\n",
       "               ...\n",
       "               '2019-01-11 15:08:07.699995500',\n",
       "                  '2019-01-11 15:08:07.699996',\n",
       "               '2019-01-11 15:08:07.699996500',\n",
       "                  '2019-01-11 15:08:07.699997',\n",
       "               '2019-01-11 15:08:07.699997500',\n",
       "                  '2019-01-11 15:08:07.699998',\n",
       "               '2019-01-11 15:08:07.699998500',\n",
       "                  '2019-01-11 15:08:07.699999',\n",
       "               '2019-01-11 15:08:07.699999500',\n",
       "                  '2019-01-11 15:08:07.700000'],\n",
       "              dtype='datetime64[ns]', length=300001, freq='500N')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='10000ns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.550000', '2019-01-11 15:08:07.550010',\n",
       "               '2019-01-11 15:08:07.550020', '2019-01-11 15:08:07.550030',\n",
       "               '2019-01-11 15:08:07.550040', '2019-01-11 15:08:07.550050',\n",
       "               '2019-01-11 15:08:07.550060', '2019-01-11 15:08:07.550070',\n",
       "               '2019-01-11 15:08:07.550080', '2019-01-11 15:08:07.550090',\n",
       "               ...\n",
       "               '2019-01-11 15:08:07.699910', '2019-01-11 15:08:07.699920',\n",
       "               '2019-01-11 15:08:07.699930', '2019-01-11 15:08:07.699940',\n",
       "               '2019-01-11 15:08:07.699950', '2019-01-11 15:08:07.699960',\n",
       "               '2019-01-11 15:08:07.699970', '2019-01-11 15:08:07.699980',\n",
       "               '2019-01-11 15:08:07.699990', '2019-01-11 15:08:07.700000'],\n",
       "              dtype='datetime64[ns]', length=15001, freq='10000N')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.550000', '2019-01-11 15:08:07.551000',\n",
       "               '2019-01-11 15:08:07.552000', '2019-01-11 15:08:07.553000',\n",
       "               '2019-01-11 15:08:07.554000', '2019-01-11 15:08:07.555000',\n",
       "               '2019-01-11 15:08:07.556000', '2019-01-11 15:08:07.557000',\n",
       "               '2019-01-11 15:08:07.558000', '2019-01-11 15:08:07.559000',\n",
       "               ...\n",
       "               '2019-01-11 15:08:07.691000', '2019-01-11 15:08:07.692000',\n",
       "               '2019-01-11 15:08:07.693000', '2019-01-11 15:08:07.694000',\n",
       "               '2019-01-11 15:08:07.695000', '2019-01-11 15:08:07.696000',\n",
       "               '2019-01-11 15:08:07.697000', '2019-01-11 15:08:07.698000',\n",
       "               '2019-01-11 15:08:07.699000', '2019-01-11 15:08:07.700000'],\n",
       "              dtype='datetime64[ns]', length=151, freq='L')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1=pd.date_range('2019-01-11 15:08:07.550','2019-01-11 15:08:07.700',freq='100ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-01-11 15:08:07.550000', '2019-01-11 15:08:07.650000'], dtype='datetime64[ns]', freq='100L')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis (g)</th>\n",
       "      <th>y-axis (g)</th>\n",
       "      <th>z-axis (g)</th>\n",
       "      <th>x-axis (deg/s)</th>\n",
       "      <th>y-axis (deg/s)</th>\n",
       "      <th>z-axis (deg/s)</th>\n",
       "      <th>participant</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.671</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>5.976</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.720</td>\n",
       "      <td>-2.073</td>\n",
       "      <td>3.171</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488</td>\n",
       "      <td>-3.537</td>\n",
       "      <td>-4.146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.070</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-5.854</td>\n",
       "      <td>3.537</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-2.805</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.382</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.462</th>\n",
       "      <td>-0.035</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.542</th>\n",
       "      <td>-0.045</td>\n",
       "      <td>-1.029</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.622</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>-1.027</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:35:13.702</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-1.031</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69677 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         x-axis (g)  y-axis (g)  z-axis (g)  x-axis (deg/s)  \\\n",
       "epoch (ms)                                                                    \n",
       "2019-01-11 15:08:04.950         NaN         NaN         NaN         -10.671   \n",
       "2019-01-11 15:08:04.990         NaN         NaN         NaN          -8.720   \n",
       "2019-01-11 15:08:05.030         NaN         NaN         NaN           0.488   \n",
       "2019-01-11 15:08:05.070         NaN         NaN         NaN           0.244   \n",
       "2019-01-11 15:08:05.110         NaN         NaN         NaN          -0.915   \n",
       "...                             ...         ...         ...             ...   \n",
       "2019-01-20 17:35:13.382      -0.060      -1.021      -0.058             NaN   \n",
       "2019-01-20 17:35:13.462      -0.035      -1.037      -0.026             NaN   \n",
       "2019-01-20 17:35:13.542      -0.045      -1.029      -0.033             NaN   \n",
       "2019-01-20 17:35:13.622      -0.039      -1.027      -0.039             NaN   \n",
       "2019-01-20 17:35:13.702      -0.049      -1.031      -0.049             NaN   \n",
       "\n",
       "                         y-axis (deg/s)  z-axis (deg/s) participant  lable  \\\n",
       "epoch (ms)                                                                   \n",
       "2019-01-11 15:08:04.950          -1.524           5.976           B  bench   \n",
       "2019-01-11 15:08:04.990          -2.073           3.171           B  bench   \n",
       "2019-01-11 15:08:05.030          -3.537          -4.146           B  bench   \n",
       "2019-01-11 15:08:05.070          -5.854           3.537           B  bench   \n",
       "2019-01-11 15:08:05.110           0.061          -2.805           B  bench   \n",
       "...                                 ...             ...         ...    ...   \n",
       "2019-01-20 17:35:13.382             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.462             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.542             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.622             NaN             NaN         NaN    NaN   \n",
       "2019-01-20 17:35:13.702             NaN             NaN         NaN    NaN   \n",
       "\n",
       "                        category   set  \n",
       "epoch (ms)                              \n",
       "2019-01-11 15:08:04.950    heavy  30.0  \n",
       "2019-01-11 15:08:04.990    heavy  30.0  \n",
       "2019-01-11 15:08:05.030    heavy  30.0  \n",
       "2019-01-11 15:08:05.070    heavy  30.0  \n",
       "2019-01-11 15:08:05.110    heavy  30.0  \n",
       "...                          ...   ...  \n",
       "2019-01-20 17:35:13.382      NaN   NaN  \n",
       "2019-01-20 17:35:13.462      NaN   NaN  \n",
       "2019-01-20 17:35:13.542      NaN   NaN  \n",
       "2019-01-20 17:35:13.622      NaN   NaN  \n",
       "2019-01-20 17:35:13.702      NaN   NaN  \n",
       "\n",
       "[69677 rows x 10 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.resample.DatetimeIndexResampler object at 0x00000251611BF0D0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged[:100].resample(rule='S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1874\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1873\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1874\u001b[0m     res_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(ser, alt, preserve_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1875\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:850\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    848\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    852\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:871\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 871\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[0;32m    872\u001b[0m     res \u001b[39m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2380\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2378\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2379\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m-> 2380\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[0;32m   2381\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[0;32m   2382\u001b[0m     )\n\u001b[0;32m   2383\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6221\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6213\u001b[0m \u001b[39m@doc\u001b[39m(make_doc(\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m   6214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m   6215\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6219\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   6220\u001b[0m ):\n\u001b[1;32m-> 6221\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11984\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11977\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m  11978\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  11979\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11982\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11983\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m> 11984\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[0;32m  11985\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m  11986\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:11941\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11939\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m> 11941\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[0;32m  11942\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[0;32m  11943\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6129\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6125\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   6126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not allow \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnumeric_only\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6127\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith non-numeric dtypes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6128\u001b[0m     )\n\u001b[1;32m-> 6129\u001b[0m \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39msum(axis, dtype\u001b[39m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\nanops.py:1693\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1692\u001b[0m     \u001b[39m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert string \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1694\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string 'BB' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_merged[:\u001b[39m100\u001b[39;49m]\u001b[39m.\u001b[39;49mresample(rule\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mmean()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:1342\u001b[0m, in \u001b[0;36mResampler.mean\u001b[1;34m(self, numeric_only, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1340\u001b[0m maybe_warn_args_and_kwargs(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, args, kwargs)\n\u001b[0;32m   1341\u001b[0m nv\u001b[39m.\u001b[39mvalidate_resampler_func(\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1342\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_downsample(\u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, numeric_only\u001b[39m=\u001b[39;49mnumeric_only)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:1728\u001b[0m, in \u001b[0;36mDatetimeIndexResampler._downsample\u001b[1;34m(self, how, **kwargs)\u001b[0m\n\u001b[0;32m   1725\u001b[0m \u001b[39m# we are downsampling\u001b[39;00m\n\u001b[0;32m   1726\u001b[0m \u001b[39m# we want to call the actual grouper method here\u001b[39;00m\n\u001b[0;32m   1727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1728\u001b[0m     result \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49mgroupby(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper)\u001b[39m.\u001b[39;49maggregate(how, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1729\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1730\u001b[0m     \u001b[39m# test_resample_axis1\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m     result \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mgroupby(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper)\u001b[39m.\u001b[39maggregate(how, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1445\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1442\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mengine_kwargs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m engine_kwargs\n\u001b[0;32m   1444\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m-> 1445\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[0;32m   1446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1447\u001b[0m     \u001b[39m# GH #52849\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_index \u001b[39mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:172\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_str()\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(func):\n\u001b[0;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_dict_like()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:586\u001b[0m, in \u001b[0;36mApply.apply_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    585\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39maxis\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\n\u001b[1;32m--> 586\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_str(obj, func, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:669\u001b[0m, in \u001b[0;36mApply._apply_str\u001b[1;34m(self, obj, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    667\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, func)\n\u001b[0;32m    668\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(f):\n\u001b[1;32m--> 669\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    671\u001b[0m \u001b[39m# people may aggregate on a non-callable attribute\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[39m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2378\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2371\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2372\u001b[0m         grouped_mean,\n\u001b[0;32m   2373\u001b[0m         executor\u001b[39m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2374\u001b[0m         engine_kwargs,\n\u001b[0;32m   2375\u001b[0m         min_periods\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   2376\u001b[0m     )\n\u001b[0;32m   2377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2378\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_agg_general(\n\u001b[0;32m   2379\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2380\u001b[0m         alt\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[0;32m   2381\u001b[0m         numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[0;32m   2382\u001b[0m     )\n\u001b[0;32m   2383\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1929\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim, alt\u001b[39m=\u001b[39malt)\n\u001b[0;32m   1927\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m-> 1929\u001b[0m new_mgr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mgrouped_reduce(array_func)\n\u001b[0;32m   1930\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1931\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1428\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[39mif\u001b[39;00m blk\u001b[39m.\u001b[39mis_object:\n\u001b[0;32m   1425\u001b[0m     \u001b[39m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m     \u001b[39m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m     \u001b[39mfor\u001b[39;00m sb \u001b[39min\u001b[39;00m blk\u001b[39m.\u001b[39m_split():\n\u001b[1;32m-> 1428\u001b[0m         applied \u001b[39m=\u001b[39m sb\u001b[39m.\u001b[39;49mapply(func)\n\u001b[0;32m   1429\u001b[0m         result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1430\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:366\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    362\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    368\u001b[0m     result \u001b[39m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    369\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1926\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1923\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1924\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m-> 1926\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_agg_py_fallback(how, values, ndim\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim, alt\u001b[39m=\u001b[39;49malt)\n\u001b[0;32m   1927\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1878\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39magg function failed [how->\u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m,dtype->\u001b[39m\u001b[39m{\u001b[39;00mser\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1877\u001b[0m     \u001b[39m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1878\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(err)(msg) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \u001b[39mif\u001b[39;00m ser\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m   1881\u001b[0m     res_values \u001b[39m=\u001b[39m res_values\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "data_merged[:100].resample(rule='S').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.columns=[\n",
    "    'acc_x',\n",
    "    'acc_y',\n",
    "    'acc_z',\n",
    "    'gyr_x',\n",
    "    'gyr_y',\n",
    "    'gyr_z',\n",
    "    'lable',\n",
    "    'category',\n",
    "    'participant',\n",
    "    'set'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z', 'lable',\n",
       "       'category', 'participant', 'set'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.695500</td>\n",
       "      <td>-1.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05</th>\n",
       "      <td>-0.002222</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>-0.071222</td>\n",
       "      <td>1.007320</td>\n",
       "      <td>-0.731720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:06</th>\n",
       "      <td>-0.099231</td>\n",
       "      <td>0.899462</td>\n",
       "      <td>-0.163846</td>\n",
       "      <td>6.978040</td>\n",
       "      <td>2.417120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07</th>\n",
       "      <td>-0.197875</td>\n",
       "      <td>1.120750</td>\n",
       "      <td>-0.124375</td>\n",
       "      <td>1.659833</td>\n",
       "      <td>-2.466222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acc_x     acc_y     acc_z     gyr_x     gyr_y\n",
       "epoch (ms)                                                           \n",
       "2019-01-11 15:08:04       NaN       NaN       NaN -9.695500 -1.798500\n",
       "2019-01-11 15:08:05 -0.002222  0.969333 -0.071222  1.007320 -0.731720\n",
       "2019-01-11 15:08:06 -0.099231  0.899462 -0.163846  6.978040  2.417120\n",
       "2019-01-11 15:08:07 -0.197875  1.120750 -0.124375  1.659833 -2.466222"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged[:100].iloc[:,:5].resample(rule='S').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.800</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.695500</td>\n",
       "      <td>-1.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.012200</td>\n",
       "      <td>-0.427000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.200</th>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-1.890400</td>\n",
       "      <td>2.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.400</th>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>-1.682600</td>\n",
       "      <td>-0.890400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.600</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>-0.064333</td>\n",
       "      <td>2.560800</td>\n",
       "      <td>-0.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.800</th>\n",
       "      <td>-0.024000</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>-0.073500</td>\n",
       "      <td>8.061000</td>\n",
       "      <td>-4.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:06.000</th>\n",
       "      <td>-0.028000</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>2.439000</td>\n",
       "      <td>-1.548600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:06.200</th>\n",
       "      <td>-0.026000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>-0.118000</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>5.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:06.400</th>\n",
       "      <td>-0.048667</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>-0.145333</td>\n",
       "      <td>21.695000</td>\n",
       "      <td>8.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:06.600</th>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.899500</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>17.524600</td>\n",
       "      <td>1.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:06.800</th>\n",
       "      <td>-0.222667</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>-0.204333</td>\n",
       "      <td>-7.231800</td>\n",
       "      <td>-1.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.000</th>\n",
       "      <td>-0.204500</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>-0.149000</td>\n",
       "      <td>-28.683000</td>\n",
       "      <td>-10.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.200</th>\n",
       "      <td>-0.205000</td>\n",
       "      <td>1.404667</td>\n",
       "      <td>-0.095000</td>\n",
       "      <td>-4.109800</td>\n",
       "      <td>-9.317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.400</th>\n",
       "      <td>-0.163500</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>35.548800</td>\n",
       "      <td>11.573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:07.600</th>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>-0.186000</td>\n",
       "      <td>5.365667</td>\n",
       "      <td>-1.544667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            acc_x     acc_y     acc_z      gyr_x      gyr_y\n",
       "epoch (ms)                                                                 \n",
       "2019-01-11 15:08:04.800       NaN       NaN       NaN  -9.695500  -1.798500\n",
       "2019-01-11 15:08:05.000       NaN       NaN       NaN  -2.012200  -0.427000\n",
       "2019-01-11 15:08:05.200  0.013500  0.977000 -0.071000  -1.890400   2.439200\n",
       "2019-01-11 15:08:05.400 -0.001500  0.970500 -0.079500  -1.682600  -0.890400\n",
       "2019-01-11 15:08:05.600  0.001333  0.971667 -0.064333   2.560800  -0.256000\n",
       "2019-01-11 15:08:05.800 -0.024000  0.957000 -0.073500   8.061000  -4.524400\n",
       "2019-01-11 15:08:06.000 -0.028000  0.957667 -0.115000   2.439000  -1.548600\n",
       "2019-01-11 15:08:06.200 -0.026000  0.965000 -0.118000   0.463400   5.219400\n",
       "2019-01-11 15:08:06.400 -0.048667  0.790000 -0.145333  21.695000   8.170800\n",
       "2019-01-11 15:08:06.600 -0.170000  0.899500 -0.250000  17.524600   1.597600\n",
       "2019-01-11 15:08:06.800 -0.222667  0.907000 -0.204333  -7.231800  -1.353600\n",
       "2019-01-11 15:08:07.000 -0.204500  0.930000 -0.149000 -28.683000 -10.207600\n",
       "2019-01-11 15:08:07.200 -0.205000  1.404667 -0.095000  -4.109800  -9.317200\n",
       "2019-01-11 15:08:07.400 -0.163500  0.996000 -0.113000  35.548800  11.573200\n",
       "2019-01-11 15:08:07.600 -0.232000  0.900000 -0.186000   5.365667  -1.544667"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged[:100].iloc[:,:5].resample(rule='200ms').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.800</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.69550</td>\n",
       "      <td>-1.7985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.01220</td>\n",
       "      <td>-0.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.200</th>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-1.89040</td>\n",
       "      <td>2.4392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.400</th>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>-1.68260</td>\n",
       "      <td>-0.8904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.600</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>-0.064333</td>\n",
       "      <td>2.56080</td>\n",
       "      <td>-0.2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:21.600</th>\n",
       "      <td>-0.174000</td>\n",
       "      <td>1.092667</td>\n",
       "      <td>-0.153333</td>\n",
       "      <td>-4.96360</td>\n",
       "      <td>-16.4026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:21.800</th>\n",
       "      <td>-0.219500</td>\n",
       "      <td>1.402500</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>-7.52440</td>\n",
       "      <td>18.6706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:22.000</th>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>-0.155667</td>\n",
       "      <td>2.60980</td>\n",
       "      <td>8.7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:22.200</th>\n",
       "      <td>-0.227000</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>5.39020</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:22.400</th>\n",
       "      <td>-0.225500</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>-0.205500</td>\n",
       "      <td>6.34125</td>\n",
       "      <td>0.5795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            acc_x     acc_y     acc_z    gyr_x    gyr_y\n",
       "epoch (ms)                                                             \n",
       "2019-01-11 15:08:04.800       NaN       NaN       NaN -9.69550  -1.7985\n",
       "2019-01-11 15:08:05.000       NaN       NaN       NaN -2.01220  -0.4270\n",
       "2019-01-11 15:08:05.200  0.013500  0.977000 -0.071000 -1.89040   2.4392\n",
       "2019-01-11 15:08:05.400 -0.001500  0.970500 -0.079500 -1.68260  -0.8904\n",
       "2019-01-11 15:08:05.600  0.001333  0.971667 -0.064333  2.56080  -0.2560\n",
       "...                           ...       ...       ...      ...      ...\n",
       "2019-01-11 15:10:21.600 -0.174000  1.092667 -0.153333 -4.96360 -16.4026\n",
       "2019-01-11 15:10:21.800 -0.219500  1.402500 -0.109000 -7.52440  18.6706\n",
       "2019-01-11 15:10:22.000 -0.192000  0.871667 -0.155667  2.60980   8.7070\n",
       "2019-01-11 15:10:22.200 -0.227000  0.891000 -0.170000  5.39020   4.0000\n",
       "2019-01-11 15:10:22.400 -0.225500  0.919500 -0.205500  6.34125   0.5795\n",
       "\n",
       "[689 rows x 5 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged[:1000].iloc[:,:5].resample(rule='200ms').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling ={\n",
    "    'acc_x': 'mean',\n",
    "    'acc_y': 'mean',\n",
    "    'acc_z': 'mean',\n",
    "    'gyr_x': 'mean',\n",
    "    'gyr_y': 'mean',\n",
    "    'gyr_z': 'mean',\n",
    "    'lable': 'first',\n",
    "    'category': 'first',\n",
    "    'participant': 'first',\n",
    "    'set':'first'\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_merged[:\u001b[39m1000\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m5\u001b[39;49m]\u001b[39m.\u001b[39;49mresample(rule\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m200ms\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(sampling)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:338\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m    331\u001b[0m     _shared_docs[\u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    332\u001b[0m     see_also\u001b[39m=\u001b[39m_agg_see_also_doc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m )\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, func\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 338\u001b[0m     result \u001b[39m=\u001b[39m ResamplerWindowApply(\u001b[39mself\u001b[39;49m, func, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49magg()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m         how \u001b[39m=\u001b[39m func\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:175\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[0;32m    176\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    177\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:406\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39magg_dict_like\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_or_apply_dict_like(op_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1388\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m: engine, \u001b[39m\"\u001b[39m\u001b[39mengine_kwargs\u001b[39m\u001b[39m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1385\u001b[0m \u001b[39mwith\u001b[39;00m com\u001b[39m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1386\u001b[0m     obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, condition\u001b[39m=\u001b[39m\u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m ):\n\u001b[1;32m-> 1388\u001b[0m     result_index, result_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_dict_like(\n\u001b[0;32m   1389\u001b[0m         op_name, selected_obj, selection, kwargs\n\u001b[0;32m   1390\u001b[0m     )\n\u001b[0;32m   1391\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1392\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:445\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m is_groupby \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[0;32m    444\u001b[0m func \u001b[39m=\u001b[39m cast(AggFuncTypeDict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\n\u001b[1;32m--> 445\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(op_name, selected_obj, func)\n\u001b[0;32m    447\u001b[0m is_non_unique_col \u001b[39m=\u001b[39m (\n\u001b[0;32m    448\u001b[0m     selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    449\u001b[0m     \u001b[39mand\u001b[39;00m selected_obj\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnunique() \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(selected_obj\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m    450\u001b[0m )\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39m# key only used for output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:639\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    637\u001b[0m     cols \u001b[39m=\u001b[39m Index(\u001b[39mlist\u001b[39m(func\u001b[39m.\u001b[39mkeys()))\u001b[39m.\u001b[39mdifference(obj\u001b[39m.\u001b[39mcolumns, sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    638\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 639\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn(s) \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(cols)\u001b[39m}\u001b[39;00m\u001b[39m do not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    641\u001b[0m aggregator_types \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    643\u001b[0m \u001b[39m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m# be list-likes\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\""
     ]
    }
   ],
   "source": [
    "data_merged[:1000].iloc[:,:5].resample(rule='200ms').apply(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z', 'lable',\n",
       "       'category', 'participant', 'set'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_merged[:\u001b[39m1000\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m5\u001b[39;49m]\u001b[39m.\u001b[39;49mresample(rule\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m200ms\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(sampling)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:338\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m    331\u001b[0m     _shared_docs[\u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    332\u001b[0m     see_also\u001b[39m=\u001b[39m_agg_see_also_doc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m )\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, func\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 338\u001b[0m     result \u001b[39m=\u001b[39m ResamplerWindowApply(\u001b[39mself\u001b[39;49m, func, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49magg()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m         how \u001b[39m=\u001b[39m func\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:175\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[0;32m    176\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    177\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:406\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39magg_dict_like\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_or_apply_dict_like(op_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1388\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m: engine, \u001b[39m\"\u001b[39m\u001b[39mengine_kwargs\u001b[39m\u001b[39m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1385\u001b[0m \u001b[39mwith\u001b[39;00m com\u001b[39m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1386\u001b[0m     obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, condition\u001b[39m=\u001b[39m\u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m ):\n\u001b[1;32m-> 1388\u001b[0m     result_index, result_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_dict_like(\n\u001b[0;32m   1389\u001b[0m         op_name, selected_obj, selection, kwargs\n\u001b[0;32m   1390\u001b[0m     )\n\u001b[0;32m   1391\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1392\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:445\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m is_groupby \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[0;32m    444\u001b[0m func \u001b[39m=\u001b[39m cast(AggFuncTypeDict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\n\u001b[1;32m--> 445\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(op_name, selected_obj, func)\n\u001b[0;32m    447\u001b[0m is_non_unique_col \u001b[39m=\u001b[39m (\n\u001b[0;32m    448\u001b[0m     selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    449\u001b[0m     \u001b[39mand\u001b[39;00m selected_obj\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnunique() \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(selected_obj\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m    450\u001b[0m )\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39m# key only used for output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:639\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    637\u001b[0m     cols \u001b[39m=\u001b[39m Index(\u001b[39mlist\u001b[39m(func\u001b[39m.\u001b[39mkeys()))\u001b[39m.\u001b[39mdifference(obj\u001b[39m.\u001b[39mcolumns, sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    638\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 639\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn(s) \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(cols)\u001b[39m}\u001b[39;00m\u001b[39m do not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    641\u001b[0m aggregator_types \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    643\u001b[0m \u001b[39m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m# be list-likes\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\""
     ]
    }
   ],
   "source": [
    "data_merged[:1000].iloc[:,:5].resample(rule='200ms').apply(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling ={\n",
    "    'acc_y':'mean',\n",
    "    'acc_z':'mean',\n",
    "    'gyr_x':'mean',\n",
    "    'acc_x':'mean',\n",
    "    'gyr_y':'mean',\n",
    "    'gyr_z':'mean',\n",
    "    'lable':'last',\n",
    "    'category':'last',\n",
    "    'participant':'last',\n",
    "    'set':'last'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_y': 'mean',\n",
       " 'acc_z': 'mean',\n",
       " 'gyr_x': 'mean',\n",
       " 'acc_x': 'mean',\n",
       " 'gyr_y': 'mean',\n",
       " 'gyr_z': 'mean',\n",
       " 'lable': 'last',\n",
       " 'category': 'last',\n",
       " 'participant': 'last',\n",
       " 'set': 'last'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_merged[:\u001b[39m1000\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m5\u001b[39;49m]\u001b[39m.\u001b[39;49mresample(rule\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m200ms\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(sampling)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:338\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m    331\u001b[0m     _shared_docs[\u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    332\u001b[0m     see_also\u001b[39m=\u001b[39m_agg_see_also_doc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m )\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, func\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 338\u001b[0m     result \u001b[39m=\u001b[39m ResamplerWindowApply(\u001b[39mself\u001b[39;49m, func, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49magg()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m         how \u001b[39m=\u001b[39m func\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:175\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[0;32m    176\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    177\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:406\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39magg_dict_like\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_or_apply_dict_like(op_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1388\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m: engine, \u001b[39m\"\u001b[39m\u001b[39mengine_kwargs\u001b[39m\u001b[39m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1385\u001b[0m \u001b[39mwith\u001b[39;00m com\u001b[39m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1386\u001b[0m     obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, condition\u001b[39m=\u001b[39m\u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m ):\n\u001b[1;32m-> 1388\u001b[0m     result_index, result_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_dict_like(\n\u001b[0;32m   1389\u001b[0m         op_name, selected_obj, selection, kwargs\n\u001b[0;32m   1390\u001b[0m     )\n\u001b[0;32m   1391\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1392\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:445\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m is_groupby \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[0;32m    444\u001b[0m func \u001b[39m=\u001b[39m cast(AggFuncTypeDict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\n\u001b[1;32m--> 445\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(op_name, selected_obj, func)\n\u001b[0;32m    447\u001b[0m is_non_unique_col \u001b[39m=\u001b[39m (\n\u001b[0;32m    448\u001b[0m     selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    449\u001b[0m     \u001b[39mand\u001b[39;00m selected_obj\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnunique() \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(selected_obj\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m    450\u001b[0m )\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39m# key only used for output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:639\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    637\u001b[0m     cols \u001b[39m=\u001b[39m Index(\u001b[39mlist\u001b[39m(func\u001b[39m.\u001b[39mkeys()))\u001b[39m.\u001b[39mdifference(obj\u001b[39m.\u001b[39mcolumns, sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    638\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 639\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn(s) \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(cols)\u001b[39m}\u001b[39;00m\u001b[39m do not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    641\u001b[0m aggregator_types \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    643\u001b[0m \u001b[39m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m# be list-likes\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\""
     ]
    }
   ],
   "source": [
    "data_merged[:1000].iloc[:,:5].resample(rule='200ms').apply(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z', 'lable',\n",
       "       'category', 'participant', 'set'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling ={'acc_x':\"mean\", 'acc_y':\"mean\", 'acc_z':\"mean\", 'gyr_x':\"mean\", 'gyr_y':\"mean\", 'gyr_z':\"mean\", 'lable':'last',\n",
    "       'category':'last', 'participant':'last', 'set':'last'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_merged[:\u001b[39m1000\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m5\u001b[39;49m]\u001b[39m.\u001b[39;49mresample(rule\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m200ms\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(sampling)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:338\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m    331\u001b[0m     _shared_docs[\u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    332\u001b[0m     see_also\u001b[39m=\u001b[39m_agg_see_also_doc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m )\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, func\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 338\u001b[0m     result \u001b[39m=\u001b[39m ResamplerWindowApply(\u001b[39mself\u001b[39;49m, func, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49magg()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m         how \u001b[39m=\u001b[39m func\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:175\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[0;32m    176\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    177\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:406\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39magg_dict_like\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_or_apply_dict_like(op_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1388\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m: engine, \u001b[39m\"\u001b[39m\u001b[39mengine_kwargs\u001b[39m\u001b[39m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1385\u001b[0m \u001b[39mwith\u001b[39;00m com\u001b[39m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1386\u001b[0m     obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, condition\u001b[39m=\u001b[39m\u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mas_index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m ):\n\u001b[1;32m-> 1388\u001b[0m     result_index, result_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_dict_like(\n\u001b[0;32m   1389\u001b[0m         op_name, selected_obj, selection, kwargs\n\u001b[0;32m   1390\u001b[0m     )\n\u001b[0;32m   1391\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1392\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:445\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    443\u001b[0m is_groupby \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[0;32m    444\u001b[0m func \u001b[39m=\u001b[39m cast(AggFuncTypeDict, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\n\u001b[1;32m--> 445\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(op_name, selected_obj, func)\n\u001b[0;32m    447\u001b[0m is_non_unique_col \u001b[39m=\u001b[39m (\n\u001b[0;32m    448\u001b[0m     selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    449\u001b[0m     \u001b[39mand\u001b[39;00m selected_obj\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnunique() \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(selected_obj\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m    450\u001b[0m )\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39m# key only used for output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:639\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    637\u001b[0m     cols \u001b[39m=\u001b[39m Index(\u001b[39mlist\u001b[39m(func\u001b[39m.\u001b[39mkeys()))\u001b[39m.\u001b[39mdifference(obj\u001b[39m.\u001b[39mcolumns, sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    638\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 639\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn(s) \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(cols)\u001b[39m}\u001b[39;00m\u001b[39m do not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    641\u001b[0m aggregator_types \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    643\u001b[0m \u001b[39m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[39m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39m# be list-likes\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['category', 'gyr_z', 'lable', 'participant', 'set'] do not exist\""
     ]
    }
   ],
   "source": [
    "data_merged[:1000].iloc[:,:5].resample(rule='200ms').apply(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>participant</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:04.800</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.69550</td>\n",
       "      <td>-1.7985</td>\n",
       "      <td>4.5735</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.01220</td>\n",
       "      <td>-0.4270</td>\n",
       "      <td>-1.6218</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.200</th>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-1.89040</td>\n",
       "      <td>2.4392</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.400</th>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>-1.68260</td>\n",
       "      <td>-0.8904</td>\n",
       "      <td>2.1708</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.600</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>-0.064333</td>\n",
       "      <td>2.56080</td>\n",
       "      <td>-0.2560</td>\n",
       "      <td>-1.4146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:21.600</th>\n",
       "      <td>-0.174000</td>\n",
       "      <td>1.092667</td>\n",
       "      <td>-0.153333</td>\n",
       "      <td>-4.96360</td>\n",
       "      <td>-16.4026</td>\n",
       "      <td>21.9026</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:21.800</th>\n",
       "      <td>-0.219500</td>\n",
       "      <td>1.402500</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>-7.52440</td>\n",
       "      <td>18.6706</td>\n",
       "      <td>-22.6828</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:22.000</th>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>-0.155667</td>\n",
       "      <td>2.60980</td>\n",
       "      <td>8.7070</td>\n",
       "      <td>-14.8658</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:22.200</th>\n",
       "      <td>-0.227000</td>\n",
       "      <td>0.891000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>5.39020</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>-0.3780</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:10:22.400</th>\n",
       "      <td>-0.225500</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>-0.205500</td>\n",
       "      <td>6.34125</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>9.9085</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            acc_x     acc_y     acc_z    gyr_x    gyr_y  \\\n",
       "epoch (ms)                                                                \n",
       "2019-01-11 15:08:04.800       NaN       NaN       NaN -9.69550  -1.7985   \n",
       "2019-01-11 15:08:05.000       NaN       NaN       NaN -2.01220  -0.4270   \n",
       "2019-01-11 15:08:05.200  0.013500  0.977000 -0.071000 -1.89040   2.4392   \n",
       "2019-01-11 15:08:05.400 -0.001500  0.970500 -0.079500 -1.68260  -0.8904   \n",
       "2019-01-11 15:08:05.600  0.001333  0.971667 -0.064333  2.56080  -0.2560   \n",
       "...                           ...       ...       ...      ...      ...   \n",
       "2019-01-11 15:10:21.600 -0.174000  1.092667 -0.153333 -4.96360 -16.4026   \n",
       "2019-01-11 15:10:21.800 -0.219500  1.402500 -0.109000 -7.52440  18.6706   \n",
       "2019-01-11 15:10:22.000 -0.192000  0.871667 -0.155667  2.60980   8.7070   \n",
       "2019-01-11 15:10:22.200 -0.227000  0.891000 -0.170000  5.39020   4.0000   \n",
       "2019-01-11 15:10:22.400 -0.225500  0.919500 -0.205500  6.34125   0.5795   \n",
       "\n",
       "                           gyr_z lable category participant   set  \n",
       "epoch (ms)                                                         \n",
       "2019-01-11 15:08:04.800   4.5735     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.000  -1.6218     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.200   0.9388     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.400   2.1708     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.600  -1.4146     B    bench       heavy  30.0  \n",
       "...                          ...   ...      ...         ...   ...  \n",
       "2019-01-11 15:10:21.600  21.9026     A    bench       heavy   1.0  \n",
       "2019-01-11 15:10:21.800 -22.6828     A    bench       heavy   1.0  \n",
       "2019-01-11 15:10:22.000 -14.8658     A    bench       heavy   1.0  \n",
       "2019-01-11 15:10:22.200  -0.3780     A    bench       heavy   1.0  \n",
       "2019-01-11 15:10:22.400   9.9085     A    bench       heavy   1.0  \n",
       "\n",
       "[689 rows x 10 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged[:1000].resample(rule='200ms').apply(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.groupby() got an unexpected keyword argument 'freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m days\u001b[39m=\u001b[39m[g \u001b[39mfor\u001b[39;00m n ,g \u001b[39min\u001b[39;00m data_merged\u001b[39m.\u001b[39mgroupby(data_merged\u001b[39m.\u001b[39;49mgroupby(freq\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mD\u001b[39;49m\u001b[39m'\u001b[39;49m))]\n",
      "\u001b[1;31mTypeError\u001b[0m: DataFrame.groupby() got an unexpected keyword argument 'freq'"
     ]
    }
   ],
   "source": [
    "days=[g for n ,g in data_merged.groupby(data_merged.groupby(freq='D'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m days\u001b[39m=\u001b[39m[g \u001b[39mfor\u001b[39;00m n ,g \u001b[39min\u001b[39;00m data_merged\u001b[39m.\u001b[39mgroupby(pd\u001b[39m.\u001b[39;49mgroupby(freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD\u001b[39m\u001b[39m'\u001b[39m))]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "days=[g for n ,g in data_merged.groupby(pd.groupby(freq='D'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=[g for n ,g in data_merged.groupby(pd.Grouper(freq='D'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                         acc_x  acc_y  acc_z   gyr_x   gyr_y  gyr_z lable  \\\n",
       " epoch (ms)                                                                  \n",
       " 2019-01-11 15:08:04.950    NaN    NaN    NaN -10.671  -1.524  5.976     B   \n",
       " 2019-01-11 15:08:04.990    NaN    NaN    NaN  -8.720  -2.073  3.171     B   \n",
       " 2019-01-11 15:08:05.030    NaN    NaN    NaN   0.488  -3.537 -4.146     B   \n",
       " 2019-01-11 15:08:05.070    NaN    NaN    NaN   0.244  -5.854  3.537     B   \n",
       " 2019-01-11 15:08:05.110    NaN    NaN    NaN  -0.915   0.061 -2.805     B   \n",
       " ...                        ...    ...    ...     ...     ...    ...   ...   \n",
       " 2019-01-11 16:24:55.706    NaN    NaN    NaN  -8.415   7.683  4.207     A   \n",
       " 2019-01-11 16:24:55.746    NaN    NaN    NaN  -4.573  -5.732  2.744     A   \n",
       " 2019-01-11 16:24:55.753  0.005 -1.022 -0.176     NaN     NaN    NaN   NaN   \n",
       " 2019-01-11 16:24:55.786    NaN    NaN    NaN   1.463 -12.195 -0.305     A   \n",
       " 2019-01-11 16:24:55.833 -0.002 -1.026 -0.189     NaN     NaN    NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-11 15:08:04.950    bench       heavy  30.0  \n",
       " 2019-01-11 15:08:04.990    bench       heavy  30.0  \n",
       " 2019-01-11 15:08:05.030    bench       heavy  30.0  \n",
       " 2019-01-11 15:08:05.070    bench       heavy  30.0  \n",
       " 2019-01-11 15:08:05.110    bench       heavy  30.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-11 16:24:55.706     dead      medium   6.0  \n",
       " 2019-01-11 16:24:55.746     dead      medium   6.0  \n",
       " 2019-01-11 16:24:55.753      NaN         NaN   NaN  \n",
       " 2019-01-11 16:24:55.786     dead      medium   6.0  \n",
       " 2019-01-11 16:24:55.833      NaN         NaN   NaN  \n",
       " \n",
       " [14549 rows x 10 columns],\n",
       "                          acc_x  acc_y  acc_z  gyr_x   gyr_y  gyr_z lable  \\\n",
       " epoch (ms)                                                                 \n",
       " 2019-01-12 15:10:08.351    NaN    NaN    NaN  0.122  -5.488 -3.841     E   \n",
       " 2019-01-12 15:10:08.391    NaN    NaN    NaN  2.195  -9.695 -0.610     E   \n",
       " 2019-01-12 15:10:08.431  0.010  0.964 -0.087  2.622  -8.110 -4.024     E   \n",
       " 2019-01-12 15:10:08.471    NaN    NaN    NaN  1.951  -4.695 -4.634     E   \n",
       " 2019-01-12 15:10:08.511  0.000  0.961 -0.069  1.524  -2.561 -2.500     E   \n",
       " ...                        ...    ...    ...    ...     ...    ...   ...   \n",
       " 2019-01-12 16:24:55.706    NaN    NaN    NaN -8.415   7.683  4.207     E   \n",
       " 2019-01-12 16:24:55.746    NaN    NaN    NaN -4.573  -5.732  2.744     E   \n",
       " 2019-01-12 16:24:55.753  0.005 -1.022 -0.176    NaN     NaN    NaN   NaN   \n",
       " 2019-01-12 16:24:55.786    NaN    NaN    NaN  1.463 -12.195 -0.305     E   \n",
       " 2019-01-12 16:24:55.833 -0.002 -1.026 -0.189    NaN     NaN    NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-12 15:10:08.351    bench       heavy  65.0  \n",
       " 2019-01-12 15:10:08.391    bench       heavy  65.0  \n",
       " 2019-01-12 15:10:08.431    bench       heavy  65.0  \n",
       " 2019-01-12 15:10:08.471    bench       heavy  65.0  \n",
       " 2019-01-12 15:10:08.511    bench       heavy  65.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-12 16:24:55.706     dead      medium  73.0  \n",
       " 2019-01-12 16:24:55.746     dead      medium  73.0  \n",
       " 2019-01-12 16:24:55.753      NaN         NaN   NaN  \n",
       " 2019-01-12 16:24:55.786     dead      medium  73.0  \n",
       " 2019-01-12 16:24:55.833      NaN         NaN   NaN  \n",
       " \n",
       " [2026 rows x 10 columns],\n",
       " Empty DataFrame\n",
       " Columns: [acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z, lable, category, participant, set]\n",
       " Index: [],\n",
       "                          acc_x  acc_y  acc_z  gyr_x   gyr_y  gyr_z lable  \\\n",
       " epoch (ms)                                                                 \n",
       " 2019-01-14 13:22:49.353    NaN    NaN    NaN -2.866  -0.610 -5.366     A   \n",
       " 2019-01-14 13:22:49.393    NaN    NaN    NaN -2.500  -0.610 -3.963     A   \n",
       " 2019-01-14 13:22:49.433    NaN    NaN    NaN  1.707  -3.902  1.524     A   \n",
       " 2019-01-14 13:22:49.473    NaN    NaN    NaN  2.439  -4.939 -4.207     A   \n",
       " 2019-01-14 13:22:49.513    NaN    NaN    NaN  7.500  -6.037  1.768     A   \n",
       " ...                        ...    ...    ...    ...     ...    ...   ...   \n",
       " 2019-01-14 14:08:59.349  0.016 -0.990 -0.110    NaN     NaN    NaN   NaN   \n",
       " 2019-01-14 14:08:59.352    NaN    NaN    NaN  4.512 -12.317 -2.683     C   \n",
       " 2019-01-14 14:08:59.392    NaN    NaN    NaN  5.610 -15.427 -0.244     C   \n",
       " 2019-01-14 14:08:59.429  0.024 -0.986 -0.061    NaN     NaN    NaN   NaN   \n",
       " 2019-01-14 14:08:59.509  0.033 -0.977 -0.055    NaN     NaN    NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-14 13:22:49.353    bench       heavy   4.0  \n",
       " 2019-01-14 13:22:49.393    bench       heavy   4.0  \n",
       " 2019-01-14 13:22:49.433    bench       heavy   4.0  \n",
       " 2019-01-14 13:22:49.473    bench       heavy   4.0  \n",
       " 2019-01-14 13:22:49.513    bench       heavy   4.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-14 14:08:59.349      NaN         NaN   NaN  \n",
       " 2019-01-14 14:08:59.352      row       heavy  49.0  \n",
       " 2019-01-14 14:08:59.392      row       heavy  49.0  \n",
       " 2019-01-14 14:08:59.429      NaN         NaN   NaN  \n",
       " 2019-01-14 14:08:59.509      NaN         NaN   NaN  \n",
       " \n",
       " [7378 rows x 10 columns],\n",
       "                          acc_x  acc_y  acc_z   gyr_x   gyr_y  gyr_z lable  \\\n",
       " epoch (ms)                                                                  \n",
       " 2019-01-15 13:22:49.353    NaN    NaN    NaN  -2.866  -0.610 -5.366     E   \n",
       " 2019-01-15 13:22:49.393    NaN    NaN    NaN  -2.500  -0.610 -3.963     E   \n",
       " 2019-01-15 13:22:49.433    NaN    NaN    NaN   1.707  -3.902  1.524     E   \n",
       " 2019-01-15 13:22:49.473    NaN    NaN    NaN   2.439  -4.939 -4.207     E   \n",
       " 2019-01-15 13:22:49.513    NaN    NaN    NaN   7.500  -6.037  1.768     E   \n",
       " ...                        ...    ...    ...     ...     ...    ...   ...   \n",
       " 2019-01-15 19:37:47.572    NaN    NaN    NaN   8.780  20.366  0.183     C   \n",
       " 2019-01-15 19:37:47.575  0.077 -1.041 -0.137     NaN     NaN    NaN   NaN   \n",
       " 2019-01-15 19:37:47.612    NaN    NaN    NaN   9.939  29.573  2.744     C   \n",
       " 2019-01-15 19:37:47.652    NaN    NaN    NaN  15.488  34.878  5.610     C   \n",
       " 2019-01-15 19:37:47.655  0.098 -1.039 -0.103     NaN     NaN    NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-15 13:22:49.353    bench       heavy  68.0  \n",
       " 2019-01-15 13:22:49.393    bench       heavy  68.0  \n",
       " 2019-01-15 13:22:49.433    bench       heavy  68.0  \n",
       " 2019-01-15 13:22:49.473    bench       heavy  68.0  \n",
       " 2019-01-15 13:22:49.513    bench       heavy  68.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-15 19:37:47.572     dead      medium  44.0  \n",
       " 2019-01-15 19:37:47.575      NaN         NaN   NaN  \n",
       " 2019-01-15 19:37:47.612     dead      medium  44.0  \n",
       " 2019-01-15 19:37:47.652     dead      medium  44.0  \n",
       " 2019-01-15 19:37:47.655      NaN         NaN   NaN  \n",
       " \n",
       " [14782 rows x 10 columns],\n",
       "                          acc_x  acc_y  acc_z  gyr_x  gyr_y   gyr_z lable  \\\n",
       " epoch (ms)                                                                 \n",
       " 2019-01-16 14:04:06.332    NaN    NaN    NaN  1.402 -6.280   1.585     E   \n",
       " 2019-01-16 14:04:06.372    NaN    NaN    NaN  1.341 -5.427   0.915     E   \n",
       " 2019-01-16 14:04:06.412    NaN    NaN    NaN -1.280  0.671  -1.829     E   \n",
       " 2019-01-16 14:04:06.452    NaN    NaN    NaN -1.829  0.366  -0.549     E   \n",
       " 2019-01-16 14:04:06.492    NaN    NaN    NaN -1.951 -2.683   1.829     E   \n",
       " ...                        ...    ...    ...    ...    ...     ...   ...   \n",
       " 2019-01-16 19:35:43.646    NaN    NaN    NaN  5.671 -1.463  10.183     E   \n",
       " 2019-01-16 19:35:43.652 -0.024 -1.044 -0.172    NaN    NaN     NaN   NaN   \n",
       " 2019-01-16 19:35:43.686    NaN    NaN    NaN  5.854 -2.988   9.512     E   \n",
       " 2019-01-16 19:35:43.726    NaN    NaN    NaN  0.915 -5.793   9.634     E   \n",
       " 2019-01-16 19:35:43.732 -0.012 -1.048 -0.124    NaN    NaN     NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-16 14:04:06.332      row       heavy  84.0  \n",
       " 2019-01-16 14:04:06.372      row       heavy  84.0  \n",
       " 2019-01-16 14:04:06.412      row       heavy  84.0  \n",
       " 2019-01-16 14:04:06.452      row       heavy  84.0  \n",
       " 2019-01-16 14:04:06.492      row       heavy  84.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-16 19:35:43.646     dead       heavy  72.0  \n",
       " 2019-01-16 19:35:43.652      NaN         NaN   NaN  \n",
       " 2019-01-16 19:35:43.686     dead       heavy  72.0  \n",
       " 2019-01-16 19:35:43.726     dead       heavy  72.0  \n",
       " 2019-01-16 19:35:43.732      NaN         NaN   NaN  \n",
       " \n",
       " [5088 rows x 10 columns],\n",
       " Empty DataFrame\n",
       " Columns: [acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z, lable, category, participant, set]\n",
       " Index: [],\n",
       "                          acc_x  acc_y  acc_z  gyr_x  gyr_y  gyr_z lable  \\\n",
       " epoch (ms)                                                                \n",
       " 2019-01-18 16:45:47.773    NaN    NaN    NaN -2.073 -0.549 -0.305     D   \n",
       " 2019-01-18 16:45:47.813    NaN    NaN    NaN -1.707 -1.220  0.061     D   \n",
       " 2019-01-18 16:45:47.853    NaN    NaN    NaN  0.122 -2.561  0.244     D   \n",
       " 2019-01-18 16:45:47.893    NaN    NaN    NaN  1.829 -2.988 -1.341     D   \n",
       " 2019-01-18 16:45:47.933    NaN    NaN    NaN  6.098 -2.439 -2.195     D   \n",
       " ...                        ...    ...    ...    ...    ...    ...   ...   \n",
       " 2019-01-18 17:35:13.616    NaN    NaN    NaN -1.220 -4.146  3.537     D   \n",
       " 2019-01-18 17:35:13.621 -0.039 -1.027 -0.039    NaN    NaN    NaN   NaN   \n",
       " 2019-01-18 17:35:13.656    NaN    NaN    NaN -0.122 -6.159  0.183     D   \n",
       " 2019-01-18 17:35:13.696    NaN    NaN    NaN -0.671 -3.171 -0.305     D   \n",
       " 2019-01-18 17:35:13.701 -0.049 -1.031 -0.049    NaN    NaN    NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-18 16:45:47.773    squat      medium  63.0  \n",
       " 2019-01-18 16:45:47.813    squat      medium  63.0  \n",
       " 2019-01-18 16:45:47.853    squat      medium  63.0  \n",
       " 2019-01-18 16:45:47.893    squat      medium  63.0  \n",
       " 2019-01-18 16:45:47.933    squat      medium  63.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-18 17:35:13.616      row      medium  61.0  \n",
       " 2019-01-18 17:35:13.621      NaN         NaN   NaN  \n",
       " 2019-01-18 17:35:13.656      row      medium  61.0  \n",
       " 2019-01-18 17:35:13.696      row      medium  61.0  \n",
       " 2019-01-18 17:35:13.701      NaN         NaN   NaN  \n",
       " \n",
       " [10692 rows x 10 columns],\n",
       "                          acc_x  acc_y  acc_z  gyr_x  gyr_y  gyr_z lable  \\\n",
       " epoch (ms)                                                                \n",
       " 2019-01-19 17:12:14.175    NaN    NaN    NaN  4.451 -6.098  0.244     E   \n",
       " 2019-01-19 17:12:14.215    NaN    NaN    NaN  3.659 -6.037  0.732     E   \n",
       " 2019-01-19 17:12:14.255    NaN    NaN    NaN  1.402 -3.902  0.915     E   \n",
       " 2019-01-19 17:12:14.295    NaN    NaN    NaN  0.305 -2.195 -0.915     E   \n",
       " 2019-01-19 17:12:14.335    NaN    NaN    NaN -1.463 -1.524 -0.610     E   \n",
       " ...                        ...    ...    ...    ...    ...    ...   ...   \n",
       " 2019-01-19 17:35:13.616    NaN    NaN    NaN -1.220 -4.146  3.537     E   \n",
       " 2019-01-19 17:35:13.621 -0.039 -1.027 -0.039    NaN    NaN    NaN   NaN   \n",
       " 2019-01-19 17:35:13.656    NaN    NaN    NaN -0.122 -6.159  0.183     E   \n",
       " 2019-01-19 17:35:13.696    NaN    NaN    NaN -0.671 -3.171 -0.305     E   \n",
       " 2019-01-19 17:35:13.701 -0.049 -1.031 -0.049    NaN    NaN    NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-19 17:12:14.175    bench      medium  69.0  \n",
       " 2019-01-19 17:12:14.215    bench      medium  69.0  \n",
       " 2019-01-19 17:12:14.255    bench      medium  69.0  \n",
       " 2019-01-19 17:12:14.295    bench      medium  69.0  \n",
       " 2019-01-19 17:12:14.335    bench      medium  69.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-19 17:35:13.616      row      medium  91.0  \n",
       " 2019-01-19 17:35:13.621      NaN         NaN   NaN  \n",
       " 2019-01-19 17:35:13.656      row      medium  91.0  \n",
       " 2019-01-19 17:35:13.696      row      medium  91.0  \n",
       " 2019-01-19 17:35:13.701      NaN         NaN   NaN  \n",
       " \n",
       " [10582 rows x 10 columns],\n",
       "                          acc_x  acc_y  acc_z  gyr_x  gyr_y  gyr_z lable  \\\n",
       " epoch (ms)                                                                \n",
       " 2019-01-20 17:22:25.756    NaN    NaN    NaN  1.341  1.463  0.671     E   \n",
       " 2019-01-20 17:22:25.796    NaN    NaN    NaN  1.098  1.098  0.976     E   \n",
       " 2019-01-20 17:22:25.836    NaN    NaN    NaN  0.183 -2.195  0.305     E   \n",
       " 2019-01-20 17:22:25.876    NaN    NaN    NaN  0.061 -2.195  0.183     E   \n",
       " 2019-01-20 17:22:25.916    NaN    NaN    NaN  0.305  0.915  1.159     E   \n",
       " ...                        ...    ...    ...    ...    ...    ...   ...   \n",
       " 2019-01-20 17:35:13.382 -0.060 -1.021 -0.058    NaN    NaN    NaN   NaN   \n",
       " 2019-01-20 17:35:13.462 -0.035 -1.037 -0.026    NaN    NaN    NaN   NaN   \n",
       " 2019-01-20 17:35:13.542 -0.045 -1.029 -0.033    NaN    NaN    NaN   NaN   \n",
       " 2019-01-20 17:35:13.622 -0.039 -1.027 -0.039    NaN    NaN    NaN   NaN   \n",
       " 2019-01-20 17:35:13.702 -0.049 -1.031 -0.049    NaN    NaN    NaN   NaN   \n",
       " \n",
       "                         category participant   set  \n",
       " epoch (ms)                                          \n",
       " 2019-01-20 17:22:25.756     rest     sitting  80.0  \n",
       " 2019-01-20 17:22:25.796     rest     sitting  80.0  \n",
       " 2019-01-20 17:22:25.836     rest     sitting  80.0  \n",
       " 2019-01-20 17:22:25.876     rest     sitting  80.0  \n",
       " 2019-01-20 17:22:25.916     rest     sitting  80.0  \n",
       " ...                          ...         ...   ...  \n",
       " 2019-01-20 17:35:13.382      NaN         NaN   NaN  \n",
       " 2019-01-20 17:35:13.462      NaN         NaN   NaN  \n",
       " 2019-01-20 17:35:13.542      NaN         NaN   NaN  \n",
       " 2019-01-20 17:35:13.622      NaN         NaN   NaN  \n",
       " 2019-01-20 17:35:13.702      NaN         NaN   NaN  \n",
       " \n",
       " [4580 rows x 10 columns]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>participant</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-12 15:10:08.351</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-5.488</td>\n",
       "      <td>-3.841</td>\n",
       "      <td>E</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 15:10:08.391</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.195</td>\n",
       "      <td>-9.695</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>E</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 15:10:08.431</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>2.622</td>\n",
       "      <td>-8.110</td>\n",
       "      <td>-4.024</td>\n",
       "      <td>E</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 15:10:08.471</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.951</td>\n",
       "      <td>-4.695</td>\n",
       "      <td>-4.634</td>\n",
       "      <td>E</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 15:10:08.511</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>1.524</td>\n",
       "      <td>-2.561</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>E</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 16:24:55.706</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.415</td>\n",
       "      <td>7.683</td>\n",
       "      <td>4.207</td>\n",
       "      <td>E</td>\n",
       "      <td>dead</td>\n",
       "      <td>medium</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 16:24:55.746</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.573</td>\n",
       "      <td>-5.732</td>\n",
       "      <td>2.744</td>\n",
       "      <td>E</td>\n",
       "      <td>dead</td>\n",
       "      <td>medium</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 16:24:55.753</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-1.022</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 16:24:55.786</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.463</td>\n",
       "      <td>-12.195</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>E</td>\n",
       "      <td>dead</td>\n",
       "      <td>medium</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-12 16:24:55.833</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>-1.026</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2026 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc_x  acc_y  acc_z  gyr_x   gyr_y  gyr_z lable  \\\n",
       "epoch (ms)                                                                 \n",
       "2019-01-12 15:10:08.351    NaN    NaN    NaN  0.122  -5.488 -3.841     E   \n",
       "2019-01-12 15:10:08.391    NaN    NaN    NaN  2.195  -9.695 -0.610     E   \n",
       "2019-01-12 15:10:08.431  0.010  0.964 -0.087  2.622  -8.110 -4.024     E   \n",
       "2019-01-12 15:10:08.471    NaN    NaN    NaN  1.951  -4.695 -4.634     E   \n",
       "2019-01-12 15:10:08.511  0.000  0.961 -0.069  1.524  -2.561 -2.500     E   \n",
       "...                        ...    ...    ...    ...     ...    ...   ...   \n",
       "2019-01-12 16:24:55.706    NaN    NaN    NaN -8.415   7.683  4.207     E   \n",
       "2019-01-12 16:24:55.746    NaN    NaN    NaN -4.573  -5.732  2.744     E   \n",
       "2019-01-12 16:24:55.753  0.005 -1.022 -0.176    NaN     NaN    NaN   NaN   \n",
       "2019-01-12 16:24:55.786    NaN    NaN    NaN  1.463 -12.195 -0.305     E   \n",
       "2019-01-12 16:24:55.833 -0.002 -1.026 -0.189    NaN     NaN    NaN   NaN   \n",
       "\n",
       "                        category participant   set  \n",
       "epoch (ms)                                          \n",
       "2019-01-12 15:10:08.351    bench       heavy  65.0  \n",
       "2019-01-12 15:10:08.391    bench       heavy  65.0  \n",
       "2019-01-12 15:10:08.431    bench       heavy  65.0  \n",
       "2019-01-12 15:10:08.471    bench       heavy  65.0  \n",
       "2019-01-12 15:10:08.511    bench       heavy  65.0  \n",
       "...                          ...         ...   ...  \n",
       "2019-01-12 16:24:55.706     dead      medium  73.0  \n",
       "2019-01-12 16:24:55.746     dead      medium  73.0  \n",
       "2019-01-12 16:24:55.753      NaN         NaN   NaN  \n",
       "2019-01-12 16:24:55.786     dead      medium  73.0  \n",
       "2019-01-12 16:24:55.833      NaN         NaN   NaN  \n",
       "\n",
       "[2026 rows x 10 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>participant</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z, lable, category, participant, set]\n",
       "Index: []"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>participant</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-14 13:22:49.353</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.866</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>-5.366</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 13:22:49.393</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>-3.963</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 13:22:49.433</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.707</td>\n",
       "      <td>-3.902</td>\n",
       "      <td>1.524</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 13:22:49.473</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.439</td>\n",
       "      <td>-4.939</td>\n",
       "      <td>-4.207</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 13:22:49.513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.500</td>\n",
       "      <td>-6.037</td>\n",
       "      <td>1.768</td>\n",
       "      <td>A</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 14:08:59.349</th>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 14:08:59.352</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.512</td>\n",
       "      <td>-12.317</td>\n",
       "      <td>-2.683</td>\n",
       "      <td>C</td>\n",
       "      <td>row</td>\n",
       "      <td>heavy</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 14:08:59.392</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.610</td>\n",
       "      <td>-15.427</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>C</td>\n",
       "      <td>row</td>\n",
       "      <td>heavy</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 14:08:59.429</th>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 14:08:59.509</th>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7378 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         acc_x  acc_y  acc_z  gyr_x   gyr_y  gyr_z lable  \\\n",
       "epoch (ms)                                                                 \n",
       "2019-01-14 13:22:49.353    NaN    NaN    NaN -2.866  -0.610 -5.366     A   \n",
       "2019-01-14 13:22:49.393    NaN    NaN    NaN -2.500  -0.610 -3.963     A   \n",
       "2019-01-14 13:22:49.433    NaN    NaN    NaN  1.707  -3.902  1.524     A   \n",
       "2019-01-14 13:22:49.473    NaN    NaN    NaN  2.439  -4.939 -4.207     A   \n",
       "2019-01-14 13:22:49.513    NaN    NaN    NaN  7.500  -6.037  1.768     A   \n",
       "...                        ...    ...    ...    ...     ...    ...   ...   \n",
       "2019-01-14 14:08:59.349  0.016 -0.990 -0.110    NaN     NaN    NaN   NaN   \n",
       "2019-01-14 14:08:59.352    NaN    NaN    NaN  4.512 -12.317 -2.683     C   \n",
       "2019-01-14 14:08:59.392    NaN    NaN    NaN  5.610 -15.427 -0.244     C   \n",
       "2019-01-14 14:08:59.429  0.024 -0.986 -0.061    NaN     NaN    NaN   NaN   \n",
       "2019-01-14 14:08:59.509  0.033 -0.977 -0.055    NaN     NaN    NaN   NaN   \n",
       "\n",
       "                        category participant   set  \n",
       "epoch (ms)                                          \n",
       "2019-01-14 13:22:49.353    bench       heavy   4.0  \n",
       "2019-01-14 13:22:49.393    bench       heavy   4.0  \n",
       "2019-01-14 13:22:49.433    bench       heavy   4.0  \n",
       "2019-01-14 13:22:49.473    bench       heavy   4.0  \n",
       "2019-01-14 13:22:49.513    bench       heavy   4.0  \n",
       "...                          ...         ...   ...  \n",
       "2019-01-14 14:08:59.349      NaN         NaN   NaN  \n",
       "2019-01-14 14:08:59.352      row       heavy  49.0  \n",
       "2019-01-14 14:08:59.392      row       heavy  49.0  \n",
       "2019-01-14 14:08:59.429      NaN         NaN   NaN  \n",
       "2019-01-14 14:08:59.509      NaN         NaN   NaN  \n",
       "\n",
       "[7378 rows x 10 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000025174B20850>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged.groupby(pd.Grouper(freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\project_python\\Full Machine Learning Project\\data-science-template-main\\data-science-template-main\\src\\data\\make_dataset.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a,c\u001b[39m=\u001b[39mdata_merged\u001b[39m.\u001b[39mgroupby(pd\u001b[39m.\u001b[39mGrouper(freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "a,c=data_merged.groupby(pd.Grouper(freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data_merged.groupby(pd.Grouper(freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled=pd.concat([df.resample(rule='200ms').apply(sampling).dropna() for df in days])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>lable</th>\n",
       "      <th>category</th>\n",
       "      <th>participant</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch (ms)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.200</th>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-1.8904</td>\n",
       "      <td>2.4392</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.400</th>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>-1.6826</td>\n",
       "      <td>-0.8904</td>\n",
       "      <td>2.1708</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.600</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>-0.064333</td>\n",
       "      <td>2.5608</td>\n",
       "      <td>-0.2560</td>\n",
       "      <td>-1.4146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:05.800</th>\n",
       "      <td>-0.024000</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>-0.073500</td>\n",
       "      <td>8.0610</td>\n",
       "      <td>-4.5244</td>\n",
       "      <td>-2.0730</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11 15:08:06.000</th>\n",
       "      <td>-0.028000</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>2.4390</td>\n",
       "      <td>-1.5486</td>\n",
       "      <td>-3.6098</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:33:27.000</th>\n",
       "      <td>-0.048000</td>\n",
       "      <td>-1.041500</td>\n",
       "      <td>-0.076500</td>\n",
       "      <td>1.4146</td>\n",
       "      <td>-5.6218</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>E</td>\n",
       "      <td>row</td>\n",
       "      <td>medium</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:33:27.200</th>\n",
       "      <td>-0.037000</td>\n",
       "      <td>-1.030333</td>\n",
       "      <td>-0.053333</td>\n",
       "      <td>-2.7684</td>\n",
       "      <td>-0.5854</td>\n",
       "      <td>2.2440</td>\n",
       "      <td>E</td>\n",
       "      <td>row</td>\n",
       "      <td>medium</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:33:27.400</th>\n",
       "      <td>-0.060000</td>\n",
       "      <td>-1.031000</td>\n",
       "      <td>-0.082000</td>\n",
       "      <td>2.8416</td>\n",
       "      <td>-5.1342</td>\n",
       "      <td>-0.1220</td>\n",
       "      <td>E</td>\n",
       "      <td>row</td>\n",
       "      <td>medium</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:33:27.600</th>\n",
       "      <td>-0.038667</td>\n",
       "      <td>-1.025667</td>\n",
       "      <td>-0.044667</td>\n",
       "      <td>-0.2318</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>1.1220</td>\n",
       "      <td>E</td>\n",
       "      <td>row</td>\n",
       "      <td>medium</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-20 17:33:27.800</th>\n",
       "      <td>-0.044000</td>\n",
       "      <td>-1.034000</td>\n",
       "      <td>-0.059000</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>-4.0240</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>E</td>\n",
       "      <td>row</td>\n",
       "      <td>medium</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9009 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            acc_x     acc_y     acc_z   gyr_x   gyr_y   gyr_z  \\\n",
       "epoch (ms)                                                                      \n",
       "2019-01-11 15:08:05.200  0.013500  0.977000 -0.071000 -1.8904  2.4392  0.9388   \n",
       "2019-01-11 15:08:05.400 -0.001500  0.970500 -0.079500 -1.6826 -0.8904  2.1708   \n",
       "2019-01-11 15:08:05.600  0.001333  0.971667 -0.064333  2.5608 -0.2560 -1.4146   \n",
       "2019-01-11 15:08:05.800 -0.024000  0.957000 -0.073500  8.0610 -4.5244 -2.0730   \n",
       "2019-01-11 15:08:06.000 -0.028000  0.957667 -0.115000  2.4390 -1.5486 -3.6098   \n",
       "...                           ...       ...       ...     ...     ...     ...   \n",
       "2019-01-20 17:33:27.000 -0.048000 -1.041500 -0.076500  1.4146 -5.6218  0.2926   \n",
       "2019-01-20 17:33:27.200 -0.037000 -1.030333 -0.053333 -2.7684 -0.5854  2.2440   \n",
       "2019-01-20 17:33:27.400 -0.060000 -1.031000 -0.082000  2.8416 -5.1342 -0.1220   \n",
       "2019-01-20 17:33:27.600 -0.038667 -1.025667 -0.044667 -0.2318  0.2562  1.1220   \n",
       "2019-01-20 17:33:27.800 -0.044000 -1.034000 -0.059000  1.0980 -4.0240  0.9760   \n",
       "\n",
       "                        lable category participant   set  \n",
       "epoch (ms)                                                \n",
       "2019-01-11 15:08:05.200     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.400     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.600     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.800     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:06.000     B    bench       heavy  30.0  \n",
       "...                       ...      ...         ...   ...  \n",
       "2019-01-20 17:33:27.000     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.200     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.400     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.600     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.800     E      row      medium  90.0  \n",
       "\n",
       "[9009 rows x 10 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                             acc_x     acc_y     acc_z   gyr_x   gyr_y   gyr_z  \\\n",
       "epoch (ms)                                                                      \n",
       "2019-01-11 15:08:05.200  0.013500  0.977000 -0.071000 -1.8904  2.4392  0.9388   \n",
       "2019-01-11 15:08:05.400 -0.001500  0.970500 -0.079500 -1.6826 -0.8904  2.1708   \n",
       "2019-01-11 15:08:05.600  0.001333  0.971667 -0.064333  2.5608 -0.2560 -1.4146   \n",
       "2019-01-11 15:08:05.800 -0.024000  0.957000 -0.073500  8.0610 -4.5244 -2.0730   \n",
       "2019-01-11 15:08:06.000 -0.028000  0.957667 -0.115000  2.4390 -1.5486 -3.6098   \n",
       "...                           ...       ...       ...     ...     ...     ...   \n",
       "2019-01-20 17:33:27.000 -0.048000 -1.041500 -0.076500  1.4146 -5.6218  0.2926   \n",
       "2019-01-20 17:33:27.200 -0.037000 -1.030333 -0.053333 -2.7684 -0.5854  2.2440   \n",
       "2019-01-20 17:33:27.400 -0.060000 -1.031000 -0.082000  2.8416 -5.1342 -0.1220   \n",
       "2019-01-20 17:33:27.600 -0.038667 -1.025667 -0.044667 -0.2318  0.2562  1.1220   \n",
       "2019-01-20 17:33:27.800 -0.044000 -1.034000 -0.059000  1.0980 -4.0240  0.9760   \n",
       "\n",
       "                        lable category participant   set  \n",
       "epoch (ms)                                                \n",
       "2019-01-11 15:08:05.200     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.400     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.600     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:05.800     B    bench       heavy  30.0  \n",
       "2019-01-11 15:08:06.000     B    bench       heavy  30.0  \n",
       "...                       ...      ...         ...   ...  \n",
       "2019-01-20 17:33:27.000     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.200     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.400     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.600     E      row      medium  90.0  \n",
       "2019-01-20 17:33:27.800     E      row      medium  90.0  \n",
       "\n",
       "[9009 rows x 10 columns]>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_resampled.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9009 entries, 2019-01-11 15:08:05.200000 to 2019-01-20 17:33:27.800000\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   acc_x        9009 non-null   float64\n",
      " 1   acc_y        9009 non-null   float64\n",
      " 2   acc_z        9009 non-null   float64\n",
      " 3   gyr_x        9009 non-null   float64\n",
      " 4   gyr_y        9009 non-null   float64\n",
      " 5   gyr_z        9009 non-null   float64\n",
      " 6   lable        9009 non-null   object \n",
      " 7   category     9009 non-null   object \n",
      " 8   participant  9009 non-null   object \n",
      " 9   set          9009 non-null   float64\n",
      "dtypes: float64(7), object(3)\n",
      "memory usage: 774.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled['set']=data_resampled['set'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9009 entries, 2019-01-11 15:08:05.200000 to 2019-01-20 17:33:27.800000\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   acc_x        9009 non-null   float64\n",
      " 1   acc_y        9009 non-null   float64\n",
      " 2   acc_z        9009 non-null   float64\n",
      " 3   gyr_x        9009 non-null   float64\n",
      " 4   gyr_y        9009 non-null   float64\n",
      " 5   gyr_z        9009 non-null   float64\n",
      " 6   lable        9009 non-null   object \n",
      " 7   category     9009 non-null   object \n",
      " 8   participant  9009 non-null   object \n",
      " 9   set          9009 non-null   int32  \n",
      "dtypes: float64(6), int32(1), object(3)\n",
      "memory usage: 739.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled.to_pickle('../../data/interim/01_data_processed.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
